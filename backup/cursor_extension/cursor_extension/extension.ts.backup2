import * as vscode from 'vscode';
import * as dotenv from 'dotenv';
import * as path from 'path';
import * as fs from 'fs';

// Load .env file from workspace root
const workspaceFolders = vscode.workspace.workspaceFolders;
if (workspaceFolders && workspaceFolders.length > 0) {
  const workspaceRoot = workspaceFolders[0].uri.fsPath;
  const envPath = path.join(workspaceRoot, '.env');
  if (fs.existsSync(envPath)) {
    dotenv.config({ path: envPath });
  } else {
    // Try parent directory (if extension is in cursor_extension subfolder)
    const parentEnvPath = path.join(workspaceRoot, '..', '.env');
    if (fs.existsSync(parentEnvPath)) {
      dotenv.config({ path: parentEnvPath });
    }
  }
} else {
  // Fallback: try current working directory
  dotenv.config();
}

import { apiClient } from './api_client';
import { registerSlackMCPCommands } from './slack_mcp_commands';

// LLM Provider type (function that takes prompt and returns response)
type LLMProvider = (prompt: string) => Promise<string>;

/**
 * Creates an LLM provider using Cursor's built-in LLM capabilities.
 * Uses Cursor's language model API (vscode.lm) which provides access to built-in LLMs.
 * No external APIs or local models - only Cursor's built-in LLMs.
 */
function createCursorLLMProvider(): LLMProvider {
  return async (prompt: string): Promise<string> => {
    // Use Cursor's built-in language model API
    // Cursor extensions have access to vscode.lm API for LLM invocations
    // Access via bracket notation to bypass TypeScript type checking
    const vscodeAny: any = vscode;
    const lm = vscodeAny['lm'] || vscodeAny.lm;
    
    if (!lm) {
      throw new Error('Cursor LLM API not available. Please ensure you are running in Cursor IDE.');
    }

    try {
      // Method 1: Try sendChatRequest (VS Code 1.80+ / Cursor API)
      if (typeof lm.sendChatRequest === 'function') {
        const response = await lm.sendChatRequest(
          [{ role: 'user', content: prompt }],
          {
            model: undefined, // Use Cursor's default model
            temperature: 0.7
          }
        );
        
        // Extract content from response
        if (typeof response === 'string') {
          return response;
        } else if (response && typeof response.content === 'string') {
          return response.content;
        } else if (response && typeof response.text === 'string') {
          return response.text;
        } else if (response && response.response) {
          return String(response.response);
        }
      }
      
      // Method 2: Try selectChatModels and use first model
      if (typeof lm.selectChatModels === 'function') {
        const models = await lm.selectChatModels();
        if (models && models.length > 0) {
          const model = models[0];
          if (model && typeof model.sendRequest === 'function') {
            const response = await model.sendRequest([
              { role: 'user', content: prompt }
            ]);
            return typeof response === 'string' ? response : String(response);
          }
        }
      }

      // Method 3: Try getLanguageModels and use first available
      if (typeof lm.getLanguageModels === 'function') {
        const models = await lm.getLanguageModels();
        if (models && models.length > 0) {
          const model = models[0];
          if (model && typeof model.sendRequest === 'function') {
            const response = await model.sendRequest([
              { role: 'user', content: prompt }
            ]);
            return typeof response === 'string' ? response : String(response);
          }
        }
      }
    } catch (error: any) {
      throw new Error(`Failed to invoke Cursor's built-in LLM: ${error.message}`);
    }

    throw new Error('Cursor LLM API available but no compatible method found. Please check Cursor version.');
  };
}

/**
 * Activates the PM Intelligence System extension.
 * Provides commands for signal ingestion, opportunity detection, judgment creation, and artifact generation.
 */
export function activate(context: vscode.ExtensionContext) {
  console.log("PM Intelligence Extension Active");
  
  // Ensure extension is activated immediately
  vscode.window.showInformationMessage('PM Intelligence Extension Activated', { modal: false }).then(() => {
    // Extension is ready
  });

  // Command: Ingest Signal
  const ingestSignalCommand = vscode.commands.registerCommand(
    'pm-intelligence.ingestSignal',
    async () => {
      const source = await vscode.window.showInputBox({
        prompt: 'Signal source (e.g., slack, teams, grafana, splunk)',
        placeHolder: 'slack'
      });
      if (!source) return;

      const text = await vscode.window.showInputBox({
        prompt: 'Signal content (raw text, no summaries)',
        placeHolder: 'Enter raw signal text...'
      });
      if (!text) return;

      const type = await vscode.window.showInputBox({
        prompt: 'Signal type',
        placeHolder: 'bug_report, feature_request, etc.'
      }) || 'unknown';

      try {
        const signal = await apiClient.ingestSignal({
          source,
          text,
          type
        });
        vscode.window.showInformationMessage(`Signal ingested: ${signal.id.substring(0, 8)}...`);
      } catch (error: any) {
        const errorMessage = error?.message || String(error);
        vscode.window.showErrorMessage(`Failed to ingest signal: ${errorMessage}`);
        console.error('Ingest signal error:', error);
      }
    }
  );

  // Command: Detect Opportunities
  const detectOpportunitiesCommand = vscode.commands.registerCommand(
    'pm-intelligence.detectOpportunities',
    async () => {
      try {
        await vscode.window.withProgress({
          location: vscode.ProgressLocation.Notification,
          title: "Detecting opportunities...",
          cancellable: false
        }, async (progress) => {
          progress.report({ increment: 0, message: "Detecting opportunities..." });
          const opportunities = await apiClient.detectOpportunities(true);
          progress.report({ increment: 100, message: "Complete!" });
          
          vscode.window.showInformationMessage(
            `Detected ${opportunities.length} opportunities`
          );
        });
      } catch (error: any) {
        const errorMessage = error?.message || String(error);
        vscode.window.showErrorMessage(`Failed to detect opportunities: ${errorMessage}`);
        console.error('Detect opportunities error:', error);
      }
    }
  );

  // Command: Create Judgment
  const createJudgmentCommand = vscode.commands.registerCommand(
    'pm-intelligence.createJudgment',
    async () => {
      try {
        // Show progress indicator
        await vscode.window.withProgress({
          location: vscode.ProgressLocation.Notification,
          title: "Loading opportunities...",
          cancellable: false
        }, async (progress) => {
          progress.report({ increment: 0, message: "Fetching opportunities..." });
          
          const opportunitiesResponse = await apiClient.getOpportunities();
          const opportunities = Array.isArray(opportunitiesResponse) ? opportunitiesResponse : (opportunitiesResponse as any).opportunities || [];
          
          if (opportunities.length === 0) {
            vscode.window.showWarningMessage('No opportunities found. Detect opportunities first.');
            return;
          }

          progress.report({ increment: 30, message: "Ready to select..." });

          const items = opportunities.map((opp: any) => ({
            label: opp.title || opp.id,
            description: opp.description || '',
            id: opp.id
          }));

          const selected = await vscode.window.showQuickPick(items, {
            placeHolder: 'Select an opportunity to create judgment for'
          });
          if (!selected) return;
          
          const opportunityId = (selected as any).id;
          const opportunityLabel = (selected as any).label;

          // Get user ID (required for human-in-the-loop)
          const userId = await vscode.window.showInputBox({
            prompt: 'Your user ID (required for human-in-the-loop)',
            placeHolder: 'user@example.com'
          });
          if (!userId) {
            vscode.window.showWarningMessage('User ID required - judgments require human-in-the-loop');
            return;
          }

          progress.report({ increment: 50, message: "Fetching signals..." });
          const signals = await apiClient.getOpportunitySignals(opportunityId);
          const opportunity = opportunities.find((opp: any) => opp.id === opportunityId);

          if (signals.length === 0) {
            vscode.window.showWarningMessage(`No signals found for opportunity ${String(opportunityLabel)}`);
            return;
          }

          progress.report({ increment: 70, message: "Creating judgment with LLM..." });

          // Build synthesis prompt
          const signalTexts = signals.map((s: any) => `- [${s.source}] ${s.text}`).join('\n');
          const prompt = `Analyze this product opportunity and provide structured reasoning.

OPPORTUNITY:
Title: ${opportunity?.title || opportunityLabel}
Description: ${opportunity?.description || 'N/A'}
Signal Count: ${signals.length}

SIGNALS:
${signalTexts}

Provide your analysis in the following format:
ANALYSIS: [Your analysis of the opportunity, customer needs, and patterns]

RECOMMENDATION: [Your recommendation on how to proceed]

ASSUMPTIONS: [List any assumptions you're making, one per line starting with "-"]

MISSING_EVIDENCE: [List any evidence that would strengthen this opportunity, one per line starting with "-"]

CONFIDENCE: [A number between 0 and 1 indicating your confidence level]`;

          const llmProvider = createCursorLLMProvider();
          const llmResponse = await llmProvider(prompt);

          // Parse LLM response
          const analysisMatch = llmResponse.match(/ANALYSIS:\s*(.+?)(?=RECOMMENDATION:|$)/is);
          const recommendationMatch = llmResponse.match(/RECOMMENDATION:\s*(.+?)(?=ASSUMPTIONS:|MISSING_EVIDENCE:|CONFIDENCE:|$)/is);
          const confidenceMatch = llmResponse.match(/CONFIDENCE:\s*([0-9.]+)/i);
          
          const analysis = analysisMatch ? analysisMatch[1].trim() : llmResponse.substring(0, 500);
          const recommendation = recommendationMatch ? recommendationMatch[1].trim() : 'Review opportunity';
          const confidence = confidenceMatch ? parseFloat(confidenceMatch[1]) : 0.5;

          progress.report({ increment: 90, message: "Saving judgment..." });

          // Save judgment via API
          const judgment = await apiClient.createJudgment({
            opportunityId: opportunityId,
            userId,
            analysis,
            recommendation,
            confidence: Math.max(0, Math.min(1, confidence)),
            reasoning: llmResponse
          });
          
          progress.report({ increment: 100, message: "Complete!" });
          
          vscode.window.showInformationMessage(
            `Judgment created: ${judgment.id.substring(0, 8)}... (confidence: ${judgment.confidence_level || 'medium'})`
          );
        });
      } catch (error: any) {
        const errorMessage = error?.message || String(error);
        vscode.window.showErrorMessage(`Failed to create judgment: ${errorMessage}`);
        console.error('Judgment creation error:', error);
      }
    }
  );

  // Command: Create Artifact
  const createArtifactCommand = vscode.commands.registerCommand(
    'pm-intelligence.createArtifact',
    async () => {
      try {
        const opportunities = await apiClient.getOpportunities();
        if (opportunities.length === 0) {
          vscode.window.showWarningMessage('No opportunities found.');
          return;
        }

        const oppItems = opportunities.map((opp: any) => ({
          label: opp.title || opp.id,
          description: opp.description || '',
          id: opp.id
        }));

        const selectedOpp = await vscode.window.showQuickPick(oppItems, {
          placeHolder: 'Select an opportunity'
        });
        if (!selectedOpp) return;
        
        const selectedOppId = (selectedOpp as any).id;

        const judgments = await apiClient.getJudgments(selectedOppId);
        if (judgments.length === 0) {
          vscode.window.showWarningMessage('No judgments found for this opportunity. Create a judgment first.');
          return;
        }

        const judgmentItems = judgments.map((j: any) => ({
          label: (j.summary || '').substring(0, 50) + '...',
          description: `Confidence: ${j.confidence_level || 'unknown'}`,
          id: j.id
        }));

        const selectedJudgment = await vscode.window.showQuickPick(judgmentItems, {
          placeHolder: 'Select a judgment'
        });
        if (!selectedJudgment) return;
        
        const selectedJudgmentId = (selectedJudgment as any).id;

        const artifactType = await vscode.window.showQuickPick(
          ['PRD', 'RFC'],
          { placeHolder: 'Select artifact type' }
        ) as 'PRD' | 'RFC' | undefined;
        if (!artifactType) return;

        const userId = await vscode.window.showInputBox({
          prompt: 'Your user ID (required for human-in-the-loop)',
          placeHolder: 'user@example.com'
        });
        if (!userId) {
          vscode.window.showWarningMessage('User ID required - artifacts require human-in-the-loop');
          return;
        }

        await vscode.window.withProgress({
          location: vscode.ProgressLocation.Notification,
          title: "Creating artifact...",
          cancellable: false
        }, async (progress) => {
          progress.report({ increment: 0, message: "Generating artifact with LLM..." });
          
          const selectedJudgmentData = judgments.find((j: any) => j.id === selectedJudgmentId);
          const llmProvider = createCursorLLMProvider();
          
          // Build artifact prompt
          const assumptions = selectedJudgmentData?.assumptions?.items || [];
          const missingEvidence = selectedJudgmentData?.missing_evidence?.items || [];
          const prompt = `Create a ${artifactType} draft based on the following judgment.

Judgment Summary: ${selectedJudgmentData?.summary || 'N/A'}
Assumptions: ${JSON.stringify(assumptions)}
Missing Evidence: ${JSON.stringify(missingEvidence)}
Confidence Level: ${selectedJudgmentData?.confidence_level || 'unknown'}

Requirements:
1. Create a complete ${artifactType} draft
2. Clearly label ALL assumptions in a dedicated "Assumptions" section
3. Include the judgment summary and analysis
4. Note any missing evidence that should be gathered
5. Use proper ${artifactType} structure and formatting

IMPORTANT: Clearly label all assumptions in the document.`;

          const artifactContent = await llmProvider(prompt);
          
          progress.report({ increment: 90, message: "Saving artifact..." });
          
          const artifact = await apiClient.createArtifact({
            judgmentId: selectedJudgmentId,
            type: artifactType,
            content: artifactContent
          });
          
          progress.report({ increment: 95, message: "Opening document..." });
          
          // Open artifact in new editor
          const doc = await vscode.workspace.openTextDocument({
            content: artifactContent,
            language: 'markdown'
          });
          await vscode.window.showTextDocument(doc);
          
          progress.report({ increment: 100, message: "Complete!" });
          vscode.window.showInformationMessage(`Artifact created: ${artifact.id?.substring(0, 8) || 'success'}...`);
        });
      } catch (error: any) {
        const errorMessage = error?.message || String(error);
        vscode.window.showErrorMessage(`Failed to create artifact: ${errorMessage}`);
        console.error('Create artifact error:', error);
      }
    }
  );

  // Command: View Signals
  const viewSignalsCommand = vscode.commands.registerCommand(
    'pm-intelligence.viewSignals',
    async () => {
      try {
        const response = await apiClient.getSignals();
        const signals = (response as any).signals || [];
        if (signals.length === 0) {
          vscode.window.showWarningMessage('No signals found.');
          return;
        }
        
        const content = signals.map((s: any) => 
          `[${s.source}] ${s.signal_type || 'unknown'}\n${(s.text || s.content || '').substring(0, 200)}\n---\n`
        ).join('\n');
        
        const doc = await vscode.workspace.openTextDocument({
          content: `# Signals (${signals.length} total)\n\n${content}`,
          language: 'markdown'
        });
        await vscode.window.showTextDocument(doc);
      } catch (error: any) {
        const errorMessage = error?.message || String(error);
        vscode.window.showErrorMessage(`Failed to view signals: ${errorMessage}`);
        console.error('View signals error:', error);
      }
    }
  );

  // Command: View Opportunities
  const viewOpportunitiesCommand = vscode.commands.registerCommand(
    'pm-intelligence.viewOpportunities',
    async () => {
      try {
        const opportunities = await apiClient.getOpportunities();
        if (opportunities.length === 0) {
          vscode.window.showWarningMessage('No opportunities found.');
          return;
        }
        
        const content = opportunities.map((opp: any) => 
          `## ${opp.title || opp.id}\n${opp.description || 'No description'}\n---\n`
        ).join('\n');
        
        const doc = await vscode.workspace.openTextDocument({
          content: `# Opportunities (${opportunities.length} total)\n\n${content}`,
          language: 'markdown'
        });
        await vscode.window.showTextDocument(doc);
      } catch (error: any) {
        const errorMessage = error?.message || String(error);
        vscode.window.showErrorMessage(`Failed to view opportunities: ${errorMessage}`);
        console.error('View opportunities error:', error);
      }
    }
  );

  // Command: View Metrics
  const viewMetricsCommand = vscode.commands.registerCommand(
    'pm-intelligence.viewMetrics',
    async () => {
      try {
        const metrics = await apiClient.getMetrics();
        
        const content = `# Adoption Metrics

## Signal Sources
${Object.entries(metrics.sources || {}).map(([source, count]: [string, any]) => 
  `- ${source}: ${count} signals`
).join('\n')}

## Opportunity Summary
- Total Opportunities: ${metrics.opportunities?.total || 0}
- High Confidence: ${metrics.opportunities?.highConfidence || 0}
- Medium Confidence: ${metrics.opportunities?.mediumConfidence || 0}
- Low Confidence: ${metrics.opportunities?.lowConfidence || 0}

## Judgments
- Total Judgments: ${metrics.judgments?.total || 0}

## Artifacts
- Total Artifacts: ${metrics.artifacts?.total || 0}
`;

        const doc = await vscode.workspace.openTextDocument({
          content,
          language: 'markdown'
        });
        await vscode.window.showTextDocument(doc);
      } catch (error: any) {
        const errorMessage = error?.message || String(error);
        vscode.window.showErrorMessage(`Failed to retrieve signals: ${errorMessage}`);
        console.error('View signals error:', error);
      }
    }
  );

  // Register Slack MCP commands
  registerSlackMCPCommands(context);

  context.subscriptions.push(
    ingestSignalCommand,
    detectOpportunitiesCommand,
    createJudgmentCommand,
    createArtifactCommand,
    viewSignalsCommand,
    viewOpportunitiesCommand,
    viewMetricsCommand
  );
}

export function deactivate() {
  // Cleanup if needed
}

