# PM Intelligence System - Environment Configuration
# Copy this file to .env and fill in your values

# ============================================================================
# DATABASE CONFIGURATION (Required)
# ============================================================================
DB_HOST=localhost
DB_PORT=5432
DB_NAME=pm_intelligence
DB_USER=postgres
DB_PASSWORD=your_password_here

# ============================================================================
# API SERVER CONFIGURATION
# ============================================================================
PORT=3000
API_HOST=localhost
NODE_ENV=development
CORS_ORIGIN=*

# ============================================================================
# LLM PROVIDER CONFIGURATION (Required for insights generation)
# ============================================================================
# Options: azure_openai, openai, chatgpt_enterprise, anthropic, cursor, mock
LLM_PROVIDER=azure_openai

# Azure OpenAI Configuration (RECOMMENDED)
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
AZURE_OPENAI_API_KEY=your-azure-openai-key-here
AZURE_OPENAI_CHAT_DEPLOYMENT=gpt-4o
AZURE_OPENAI_CHAT_API_VERSION=2024-08-01-preview

# OpenAI Configuration (alternative)
# OPENAI_API_KEY=sk-your-key-here
# OPENAI_MODEL=gpt-4-turbo-preview
# OPENAI_BASE_URL=https://api.openai.com/v1

# ChatGPT Enterprise Configuration (OpenAI-compatible)
# CHATGPT_ENTERPRISE_API_KEY=your-chatgpt-enterprise-key
# CHATGPT_ENTERPRISE_MODEL=gpt-4o
# CHATGPT_ENTERPRISE_BASE_URL=https://your-enterprise-endpoint/v1

# Anthropic Configuration (if using)
# ANTHROPIC_API_KEY=sk-ant-your-key-here
# ANTHROPIC_MODEL=claude-3-opus-20240229

# LLM Options
# LLM_TEMPERATURE=0.7
# LLM_MAX_TOKENS=4096
AZURE_REQUEST_TIMEOUT_MS=30000
AZURE_RETRY_MAX_ATTEMPTS=4
AZURE_RETRY_BASE_DELAY_MS=500
AZURE_RETRY_MAX_DELAY_MS=10000

# Readiness failure gates
READINESS_MAX_REMAINING_FAILED=0
READINESS_MAX_REMAINING_FAILED_RATE=0

# Optional Python services (enable corresponding feature flags)
# DOCUMENT_PARSER_URL=http://localhost:8001
# GRAPHRAG_INDEXER_URL=http://localhost:8002

# ============================================================================
# EMBEDDING PROVIDER CONFIGURATION (Required for semantic search)
# ============================================================================
# Options: azure_openai, openai, cohere, cursor, mock
EMBEDDING_PROVIDER=azure_openai

# Azure OpenAI Embeddings (RECOMMENDED)
AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT=text-embedding-ada-002
AZURE_OPENAI_EMBEDDINGS_API_VERSION=2023-05-15
# Note: Uses AZURE_OPENAI_ENDPOINT and AZURE_OPENAI_API_KEY from above

# OpenAI Embeddings (alternative)
# Uses OPENAI_API_KEY from above
# EMBEDDING_MODEL=text-embedding-3-large
# EMBEDDING_DIMENSIONS=1536

# Cohere Embeddings (if using)
# COHERE_API_KEY=your-cohere-key-here
# COHERE_EMBEDDING_MODEL=embed-english-v3.0

# ============================================================================
# SLACK INTEGRATION (Optional)
# ============================================================================
# For MCP-based Slack ingestion
# SLACK_MCP_SERVER=your-mcp-server-url

# For direct Slack API access
SLACK_BOT_TOKEN=xoxb-your-bot-token-here
# SLACK_APP_TOKEN=xapp-your-token

# Multi-Channel Batch Ingestion (V2)
# Comma-separated list of channel IDs to ingest from
SLACK_CHANNEL_IDS=C04D195JVGS,C08T43UHK9D
SLACK_BATCH_SIZE=200
SLACK_MAX_MESSAGES_PER_CHANNEL=10000
SLACK_INCLUDE_THREADS=true

# Slack Notifications (for cost tracking alerts)
# Create an incoming webhook at: https://api.slack.com/messaging/webhooks
# SLACK_WEBHOOK_URL=https://hooks.slack.com/services/YOUR/WEBHOOK/URL

# ============================================================================
# EMAIL NOTIFICATIONS (Optional)
# ============================================================================
# Pipeline completion email summary with final JIRA table
SMTP_HOST=inner-relay-1.corp.adobe.com
SMTP_PORT=25
EMAIL_FROM=pm-intelligence-system@adobe.com
EMAIL_TO=anusharm@adobe.com

# ============================================================================
# RATE LIMITING
# ============================================================================
# Set to true ONLY for local development
DISABLE_RATE_LIMITING=false
RATE_CTRL_MIN_CONCURRENCY=1
RATE_CTRL_MAX_CONCURRENCY=20
RATE_CTRL_INITIAL_CONCURRENCY=3
RATE_CTRL_LATENCY_THRESHOLD_MS=4000
RATE_CTRL_COOLDOWN_MS=3000

# ============================================================================
# LOGGING
# ============================================================================
# Global log level: error, warn, info, debug, trace
# - error: Only critical failures
# - warn: Fallback behaviors, degraded functionality
# - info: Operation start/complete, user actions (default for production)
# - debug: Detailed operation steps, decision points, intermediate results
# - trace: Ultra-detailed debugging (every comparison, full LLM prompts/responses)
LOG_LEVEL=info

# Module-specific log levels (override global LOG_LEVEL)
# Uncomment and set to enable detailed logging for specific modules

# Opportunity clustering & merge operations
# LOG_LEVEL_OPPORTUNITY=debug
# Progress log cadence for long opportunity clustering/merge loops
# - lower value = more frequent progress logs
# - recommended: 500 for normal runs, 100 for deep troubleshooting
# OPPORTUNITY_CLUSTER_PROGRESS_EVERY=500

# Entity matching & merge operations
# LOG_LEVEL_ENTITY_RESOLUTION=debug

# JIRA issue generation (LLM calls, context prep, timing)
# LOG_LEVEL_JIRA=debug
# For deep troubleshooting, use LOG_LEVEL_JIRA=debug with monitor script enabled

# Data exports (audit trail, row counts, query timing)
# LOG_LEVEL_EXPORT=info

# All LLM operations (prompts, responses, timing)
# LOG_LEVEL_LLM=debug

# Database operations (query timing, connection pool)
# LOG_LEVEL_DATABASE=warn

# ============================================================
# Infrastructure & Utilities
# ============================================================
# Correlation ID middleware and context propagation
# LOG_LEVEL_CORRELATION=info

# LRU cache operations (hit/miss, evictions)
# LOG_LEVEL_CACHE=info

# Retry logic and circuit breaker state
# LOG_LEVEL_RETRY=info

# Redis connection management
# LOG_LEVEL_REDIS=info

# Health check endpoints
# LOG_LEVEL_HEALTH=info

# ============================================================
# Services
# ============================================================
# Failed signal retry mechanism
# LOG_LEVEL_FAILED_SIGNAL_RETRY=info

# File upload validation (detailed step-by-step validation)
# LOG_LEVEL_FILE_VALIDATION=debug

# Website crawling operations
# LOG_LEVEL_WEBSITE_CRAWLER=info

# Hybrid search operations
# LOG_LEVEL_HYBRID_SEARCH=info

# Note: Security audit logs (auth, permissions, admin operations)
# are always logged at INFO level and cannot be disabled.

# ============================================================================
# FEATURE FLAGS
# ============================================================================
# Enable Role-Based Access Control (not yet implemented)
ENABLE_RBAC=false

# ============================================================================
# ADVANCED: PGVECTOR CONFIGURATION
# ============================================================================
# pgvector is automatically installed via migrations if available
# If you need to configure HNSW index parameters:
# HNSW_M=16
# HNSW_EF_CONSTRUCTION=64

# ============================================================================
# V2: NEO4J CONFIGURATION
# ============================================================================
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=neo4jpassword
NEO4J_DATABASE=neo4j
NEO4J_TIMEOUT_MS=10000

# ============================================================================
# V2: REDIS CONFIGURATION
# ============================================================================
REDIS_URL=redis://localhost:6379
REDIS_PASSWORD=changeme

# ============================================================================
# V2: ENTITY RESOLUTION
# ============================================================================
ER_AUTO_MERGE_THRESHOLD=0.9
ER_HUMAN_REVIEW_THRESHOLD=0.6
ER_REJECT_THRESHOLD=0.3

# ============================================================================
# V2: MCP SERVER
# ============================================================================
MCP_SERVER_PORT=3001
MCP_SERVER_NAME=pm-intelligence
MCP_BIND_HOST=127.0.0.1
MCP_API_KEY=

# ============================================================================
# V2: TWO-PASS LLM EXTRACTION
# ============================================================================
AZURE_OPENAI_FAST_DEPLOYMENT=gpt-4o-mini
LLM_FAST_TEMPERATURE=0.3
LLM_FAST_MAX_TOKENS=2048

# ============================================================================
# V2: DOCUMENT INGESTION
# ============================================================================
UPLOAD_DIR=./data/uploads
MAX_FILE_SIZE_MB=50
MAX_BATCH_FILES=20
INGESTION_CONCURRENCY=5
INGESTION_BATCH_EXTRACTION=true
LLM_EXTRACTION_BATCH_CONCURRENCY=5
INGESTION_SIGNAL_TIMEOUT_MS=60000
SUPPORTED_FORMATS=pdf,docx,pptx,xlsx,csv,txt,vtt,srt
UPLOAD_RETENTION_HOURS=24

# ============================================================================
# FORUM SCRAPER (Dockerized Selenium)
# ============================================================================
# Default forum key used by docker-compose forum-scraper service
FORUM_SCRAPER_FORUM=aem-forms
# Optional max page/load-more iteration limit (empty = no explicit cap)
FORUM_SCRAPER_MAX_PAGES=
# Per-page delay in seconds
FORUM_SCRAPER_DELAY=2
# Optional date filter for retained threads (YYYY-MM-DD)
FORUM_SCRAPER_SINCE=
# Optional test limit for fast validation runs
FORUM_SCRAPER_TEST_LIMIT=

# ============================================================================
# V2: RETENTION POLICIES
# ============================================================================
SIGNAL_RETENTION_DAYS=365
METRICS_RETENTION_DAYS=30
EVENT_TTL_DAYS=7

# ============================================================================
# V2: AGENT GATEWAY
# ============================================================================
AGENT_RATE_LIMIT_RPM=60
AGENT_MAX_MONTHLY_COST_USD=50
AGENT_REGISTRATION_SECRET=change_me
START_EVENT_DISPATCHER=false
START_CLEANUP_JOBS=false
START_INGESTION_SCHEDULER=false
INGESTION_SCHEDULER_INTERVAL_MINUTES=60

# ============================================================================
# V3: COST TRACKING & MONITORING
# ============================================================================
# Enable/disable cost tracking system
FF_COST_TRACKING=true

# Pricing tier: development (zero costs for testing) or production (actual costs)
COST_TRACKING_TIER=production

# Batch configuration for cost recording
COST_BATCH_SIZE=50
COST_FLUSH_INTERVAL_MS=5000

# Default monthly budget per agent (can be overridden per agent via API)
AGENT_MAX_MONTHLY_COST_USD=50

# ============================================================================
# V2: FEATURE FLAGS (true/false)
# ============================================================================
# Phase 1-2 features (enable from start)
FF_NEO4J_SYNC=true
FF_TWO_PASS_LLM=true
FF_HALLUCINATION_GUARD=true

# Phase 3-4 features (enable when ready)
FF_GRAPHRAG_INDEXER=false
FF_A2A_SERVER=false
FF_AGENT_GATEWAY=false
FF_EVENT_BUS=false
FF_STAKEHOLDER_ACCESS=false
FF_ER_LLM_CONFIRMATION=false