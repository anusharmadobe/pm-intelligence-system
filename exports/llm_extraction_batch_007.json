[{"signal_id" : "9bf9dd92-4484-4a03-b797-c50a35b25ba7", "text" : "*\n• The proposal was well received and we have moved to next stage of RFP. \n• A call with reference customer from Austria, Constantia Teich is scheduled on April 22, 2025. \n• Post this, we will move to next stage of RFP where we will have to present a custom demo of IC on CS to them. \n:todo_done: *"}, {"signal_id" : "d53f20bc-db51-4dbc-8fa5-da61e723fea6", "text" : "*\n• A general discussion happened around how would we handle DB’s migration from older CM to IC on CS. \n• We discussed about VIP engagement to to do a pilot migration of couple of letters. As an outcome of this VIP, these letters should be live on CS and we should have an approach in place to migrate rest of the DB assets block by block. \n:todo_done: *"}, {"signal_id" : "115864f8-323f-452d-a51d-fd4ca7534240", "text" : "*\n*Discussion on Accessibility Issues in INAIL Forms:*\n• We reviewed the accessibility issues related to the forms being created by INAIL.\n• The accessibility team provided several comments, which can be resolved if the correct structure is established by the form designer during the template creation phase in AEM designer\n• We discussed around how the checkboxes should be read by the screen reader when the state is checked or unchecked. This can also be handled if the template is created in the right way using AEM Designer.\n:todo_done: *"}, {"signal_id" : "5c0b47f9-f9b4-4e94-a9e5-bcda046dd256", "text" : "*\n*Major pain points for Customer that we need to handle in VIP Engagement:*\n• *Scalability Issues:* Scalability has been identified as a major challenge, it takes significant time and effort  to design and bind a large number of forms.\n• *Binding Steps:* The current process involves few steps like binding in XDP , changing in transformation code etc , making it inefficient and time-consuming.\n• *Framework Limitations:* The existing framework does not scale effectively for a large number of forms. Each new form requires manual mapping and binding, which is unsustainable for the 2,000-3,000 forms that need to be converted.\nWe need to provide the approach via which customer can successfully transform their pending forms is scalable manner (if possible via some automation)\n\n*Summary:*\n• The incoming JSON does not follow a standard schema and may change with new forms and fields.\n• Currently, for each new form, customers must manually design it in the Designer. If new fields are added, they also need to update the transformation code and XSD schema.\n• The customer mentioned that they have several mandatory forms for specific customers, implemented via Adaptive Forms for data capturing. Data from these forms will be included in the incoming JSON and used to generate PDFs via the Output Service. We plan to discuss this further in upcoming meetings.\n• Additionally, the customer mentioned that they still need to migrate 2,000-3,000 forms.\n*Topics for upcoming meetings:*\n• The usage of Adaptive Forms and their integration into the incoming JSON.\n• *Analyze Metadata Call:* Explain and show the process of retrieving form metadata and its necessity in the workflow.\n• *Review Custom Endpoint:* Discuss the custom endpoint of PDF generation and what additional steps are being performed in that.\n:todo_done: *"}, {"signal_id" : "002fb8e6-4615-4c9a-b2e9-b1660f641972", "text" : "*\n*Use-Case*\n\n• The current solution Unipol uses for generating PDFs is Pega. They have integrated it in their product and uses it to define the template for communications.\n• The template is composed of multiple sections and rules are defined on them for dynamic content. Rules are data based and data is coming from external service/database.\n• PDFs are generated on demand as well as in batches(1000letters).\n• The use-case is to migrate from Pega.\nCommunication Composer was presented to the Partner Reply and they showed interest and wanted to try it on their end.\n:todo_done: *"}, {"signal_id" : "ff7adef4-10e5-46eb-950e-3d6ceedf694a", "text" : "*\nHad Meeting with NFCU Engineers (Ashish and Ashwairya).\n• NFCU is looking for dates for MVP features to their usecase primarily FDM, Render API, Basic Rules.\n• Informed them that by *May end* these features should be available, showcased that we are tracking the sheet where they shared their requirements.\n• They are creating use-case to showcase to their Business, after which go-live date would be decided.\n• Engineering sessions are helping and NFCU wants to get regular updates to their env.\n:todo_done: *"}, {"signal_id" : "92bc5c3e-a813-400a-9d0a-c8b09f179c5a", "text" : "*\n• The customer explained their workflow for fetching the metadata required for e-signature and described the Output Service custom endpoint.\n• They are making two calls to the AEM repository: one to fetch metadata and another to fetch the template based on formID. This second call is redundant since the template path is already included in the metadata.\n• They confirmed that they start designing the forms from scratch, adding fields to create the XDPs (similar to the PDF forms they intend to migrate to AEM Forms). So far, they have designed around 50 forms.\n• They mentioned using fragments for common business logic across different workflows, such as new account openings.\n\n:todo_done: *"}, {"signal_id" : "c962b8c2-835a-4bd6-bab7-489aeb451eb5", "text" : "*\n*Attendees:*\n• Adobe Engineering, Consulting &amp; License\n• Accenture Federal Technical, Program, and Account Resources\n*Agenda:*\n• Forms Categorization/Prioritization\n• Technology Approach\n• Core Components\n• Forms Converter Tooling – Forms Automation Resources\n*Key Discussions:*\n1. *Overall Customization* :\n    ◦ *Wizard Customization*: Extended to meet styling guides and JavaScript requirements. \n    ◦ *Summary Component*: Implemented to display errors as users move to the next section of the form. \n    ◦ *Review Component*: Generates a table listing all form fields before submission, leveraging the JSON model. \n    ◦ *Signature Component*: Custom component for signature, which includes a checkbox and hidden text boxes to meet specific data structure requirements. \n    ◦ *SSN Field*: Custom field for Social Security Number (SSN). \n    ◦ *Save as Draft*: Custom implementation using Postgres database, extending the default save as draft functionality. \n    ◦ *Multi-Signature Solution*: Custom solution for handling multiple signatures, including user verification and form ownership transfer. \n    ◦ *Templates*: There are three different templates used:\n        ▪︎ *No Authentication Template*: For forms that do not require user authentication.\n        ▪︎ *Single Signature Template*: For forms requiring a single signature.\n        ▪︎ *Multi-Signature Template*: For forms requiring multiple signatures.\n2. Current Process of PDF to AF\n    ◦ *XDP Source*: The forms are received as XDP files, which include the XML schema and data dictionary. \n    ◦ *Form Creation Process*: The process involves dragging the XML schema onto the form to create the initial structure. This is followed by implementing business logic and ensuring compliance with 508 requirements. \n    ◦ *Time-Consuming*: The creation of forms takes weeks due to the extensive setup, validation, and adjustments required. \n    ◦ *Business Logic and Validation*: A significant amount of time is spent on implementing business logic and validating the forms with form owners. \n    ◦ *508 Compliance*: Ensuring 508 compliance adds to the complexity and time required for form creation. \n3. *Challenges in current process*:\n    ◦ *Complex Customization*: The signature component, which was previously a fragment with multiple hidden text boxes and a checkbox, required significant setup and was prone to errors by authors. This complexity made it difficult to maintain and use consistently. \n    ◦ *Performance Issues*: The editor for the foundation components was slow and inefficient. For example, moving a panel to a different section often required reloading the entire editor, which significantly slowed down the form creation process. \n    ◦ *Business Logic Implementation*: Implementing business logic and ensuring compliance with 508 requirements (accessibility standards) added to the complexity and time required to create forms. Each component needed detailed configuration to meet these standards. \n    ◦ *Non-Deterministic Process*: The process of converting PDFs to digital forms involved continuous interaction with form owners to capture business rules and validations, making the process non-deterministic and time-consuming. \n    ◦ *Technical Debt*: Using foundation components for new forms would create technical debt, as the core components are seen as the future direction for better maintainability and performance.\n4. *Current Plan*:\n    ◦ Continue using foundation components to avoid uncertainties and risks.\n    ◦ Parallel effort to develop and test core components, including reworking \"save as draft\" and implementing JSON to XML conversion. \n\n:todo_done: *"}, {"signal_id" : "8c93e9ca-06be-4334-8951-a921f94909a1", "text" : "*\nDiscussion Summary with NFCU -\n1. *Font Subset Embedding:* NFCU requested the ability to embed font subsets during PDF preview. We clarified that this feature is available when generating PDFs using the output service with XCI. However, it is not currently supported for PDF previews.\n2. *Nested Table Support:* NFCU asked if nested table support would be included in the next release. We responded that this feature is currently not available.\n3. *Repeatable Subform Support in Tables:* NFCU inquired about adding dynamic capabilities to tables. We explained that this can be achieved using repeatable subforms, although this feature is not yet available in the editor.\n4. *Template as Reference:* NFCU requested the use of templates as references. We highlighted potential layout challenges with this approach and suggested trying it with fragments instead.\n5. *Web Hooks:* NFCU inquired about the possibility of implementing web hooks for customization purposes, either post-rendering or pre-rendering. We informed them that currently, we do not support any customization beyond the editor.\n6. *FDM-Related Queries for NFCU:*\n    a. Storage Data Source: We sought information about the storage data source.\n    b. API Details: We inquired about the availability of a Swagger endpoint or file for their REST API.\ncc: <@WQWCBV6NN> <@W4R5LUPK3> <@W9QMZFR39>\n:todo_done: *"}, {"signal_id" : "a3ae5f6b-c36e-4c6d-8fbd-c908e40ac2ad", "text" : "*\n• Demonstrated Forms Experience Builder for core components as well as for EDS forms.\n• Demonstrated Automated Test case generation capability for validating their forms .\n• Customer Queries - if assistant can work with custom components, if it can answer queries about integration with external sources etc. \n• Customer shared they have about 50 lead generation forms with a 3.5% conversion rate. They were interested in increasing the conversion rates and Success Studio was suggested as a project to improve conversion rates.\n• Customer explained their current manual process for form versioning by duplicating forms and using folder hierarchy but the versioning capabilities in forms was proposed since it can help the customer achieve this.\n:todo_done: *"}, {"signal_id" : "5628f44e-9dbf-4fd4-91bd-4d1a6fcd5e73", "text" : "*\nGlidewell Dental's setup issue was resolved during the call.\n:todo_done: *"}, {"signal_id" : "b75128b3-f401-443c-b4c3-9964aadf5c4b", "text" : "*\nCustomers:\n• Martin, George\n• Muravitsky, Valerie\n• Petty, Michael\n• Teague, Stephanie\n• Kolluru, Abhishek\n• Paracka, Jacob J\n*Installation*: On Prem\n\n*Background:* We had a meeting with the customer at the summit and it was a follow up to that. They have XDP forms which are present as links in mutliple websites. The customers fill those forms , print it and post it. They want to digitalize this use case using HTML5 Forms and have some questions around that. During the summit they clearly mentioned they are not planning to move to Adaptive Form currently.\n\nThe team has shared the questions earlier in the mail and we had a discussion around the same.\n\nTheir current architecture that they have tried is that they have a custom servlet which forwards the request to the HTML5 Form rendition and returns that. Then they have an external website which either embeds the Form as iframe or redirects to the AEM Servlet which forwards to the HTML5 Form rendition profile.\n\n1. They wanted a validation of the above strategy and if possible to hide certain parameters from the request. _*Advised them to have sling mapping or some selector based notion to identify the xdp path in their servlet.*_\n2. They have another use case (non iframe), where they want to fetch the HTML from an application or a web app and then insert the HTML in that page. This is also possible with the way we do it for Adaptive Forms, but we need to implement it for HTML5 Forms as well. _*They have asked for a sample if possible.*_ \n3. They currently use an http url to fetch the data but want to hide that url. _*Advised them to provide a prefill service that can take an id and then use that service to fetch the data. Clearly mentioned that we do not store any data in AEM to ease out their security concerns.*_ \n4. They want to cache the HTML content in dispatcher. _*Mentioned that it needs to be supported on 6.5 and they need to raise a new Feature Request for the same.*_\n5. Discussed with them how complex their xdps are and they mentioned they only have some validation rules in the xdps.\n6. Arun asked about cloud migration and they asked for a write up from us on what are the differences between the on-prem version vs Cloud so that they can get a buy in from the higher management\n\n:todo_done: *"}, {"signal_id" : "7134ca54-f0e7-4883-898c-c6bad4874156", "text" : "*\n*Use Case:*\n Abbvie intends to automatically save a draft whenever a form submission is triggered. They also want to implement a service that can query these drafts based on form type and timestamp and will process these drafts.\n\n*Discussion Summary:*\n• We proposed enhancing the \"Submit Form\" rule to include a \"Save Form\" action. A demo of this functionality was presented during the meeting.\n• For querying drafts, we have shown the metadata associated with each draft entry. This metadata can be used to filter and retrieve drafts as required.\n• Abbvie inquired about the draft retention policy, which was addressed during the session.\n• Abbvie also expressed the need to encrypt the draft data instead of storing it as plain text, due to the inclusion of PII data.\n\n:todo_done: *"}, {"signal_id" : "58c68758-c556-4b31-84a4-aa4050b6204f", "text" : "*\nUse case:\nACS team reaches out to us to review their custom function regarding for previous and next button in tab. As, they were not aware of using globals and were not sure how to pass field object to custom function.\n\nWhile reviewing their custom code, I recommended them to use three latest features of Visual rule editor which are:\n1. Enhanced invoke service to use condition in success handler.\n2. Add condition with button click.\n3. Add valid/invalid condition at panel level in when.\nAfter using these features, they were able to reduce almost 100 lines of custom code from their js (total lines were 268).\n\ncc: <@W4R5LUPK3> <@U02DW7JLT62>\n:todo_done: *"}, {"signal_id" : "27c0e668-a599-45a2-a206-831ae2693190", "text" : "*\nTFS - Existing IC customer on AMS had connect with Arun during Summit, where they are interested in Cloud based IC, as part of moving to Cloud.\n• 30% of their usecase is PDF generation - No issues in this flow\n• 70% of their usecase is AgentsUI, where TFS Customer representatives fill in the data in static form and generated PDF.\n• They have shared list of issues in existing IC which they want an ETA.\n• Also looking for Roadmap of IC on cloud.\ncc: <@W9QMZFR39>\n:todo_done: *"}, {"signal_id" : "3abf3de9-fc63-4de1-87c0-6cf1447d463f", "text" : "*\n*Support of `$record` and `$data` API in HTML5 Forms*\n• The customer has tested *hundreds of forms* using the `resolveNodes()` API and *thousands of XDP-to-HTML5 form conversions*.\n•  ➤ All issues observed are either *known* or *minor*, and *do not impact form functionality*.\n• The *go-live* for the first batch of forms is scheduled in *6 weeks*.\n•  ➤ Rollouts will continue across *different departments throughout the year*.\n• The customer is using *third-party fonts* in HTML5 forms.\n•  ➤ The *font specified in the XDP template is not present on client machines*, so the browser defaults to another font (e.g., Arial).\n•  ➤ This *default font sometimes renders random characters*, which is *not aligned with expected rendering* from AEM’s server-side engine.\n• Suggested approach: ➤ Create a *custom HTML5 profile* that:\n    ◦ Includes your *own fonts* as web resources\n    ◦ Loads fonts via CSS using `@font-face`\n    ◦ Applies fonts to the rendered form using *CSS overrides*\n\n:todo_done: *"}, {"signal_id" : "e59b90d7-cca4-4b4b-98fa-bf69d327f471", "text" : "*\nCustomer: Sreedhar, Ashish, Monika and others\n• :tada: After almost 2 years of VIP engagement, NFCU has gone live with AEM Forms Output (with their custom implementation), with one of their departments (DSC) with a small Subset. \n• Another Department (Admin services) there is workshop/demo meeting where the NFCU team wants to showcase IC on Cloud capabilities and looking forward for the MVP features targeted by May end.\n• NFCU is also looking for support of dynamic Tables which currently is out of May end target.\n• All the changes should be behind FT and we need to make it part of the release, as after validation, NFCU wants to take it to other envs (Stage, Prod)\ncc: <@W4RSW3ECC> <@W5HEU5M7Y> <@W9QMZFR39> <@WQWCBV6NN>\n:todo_done: *"}, {"signal_id" : "2bf9ee3e-e687-4e02-942b-ae789a8a264d", "text" : "*\n*Agenda:*\n• IRS is in the process of migrating a couple of their multi-signer forms to Core Components and time line is end of June.\n• Accenture is acting as the implementation partner for this migration.\n• Accenture wanted to discuss following topics in this call.\n1. *Save as Draft Functionality:*\n    a. Accenture was unable to locate documentation related to the \"Save as Draft\" feature for Core Component-based forms in the on-premise setup.\n    b. We clarified that the draft functionality is currently not available for Core Component-based forms on 6.5 and will need to be back ported.\n    c. A tentative timeline of 4–5 weeks was provided for the availability of this functionality.\n    d. We also clarified that once the draft capability is back ported, Accenture will need to rewrite their customization for PostgreSQL accordingly.\n    e. Accenture highlighted the need for draft functionality in their multi-signer process, as they update the owner information when the second signer logs in. We confirmed that similar functionality will be achievable with the new implementation.\n2. *Custom Submission:*\n    a. Accenture inquired whether request header information can be accessed in custom submission service, as their backend logic depends on it.\n    b. We confirmed this needs to be checked, and if not feasible, Accenture may proceed to implement a custom servlet for submission.\n3. *Core Component JSON to XML Conversion:*\n    a. Accenture asked if there is any OOTB (Out-of-the-Box) utility available to convert Core Component JSON data to XML, as their current services are designed to consume XML and if not present, then they would need to implement their own custom converter.\n:todo_done: *"}, {"signal_id" : "4fdbf0e6-38a5-4c4c-a90e-22c1cb2a6425", "text" : "*\n• *PDF Import Demonstration: W*e demonstrated the process of importing a PDF(customer legacy form) into the designer, highlighting the options available and that can produce the XDP. we also explained how it can address text overlapping issue. It should reduce their manual work to 80-90%.\n• *Manual Adjustments -* some manual adjustments will still be necessary, such as missing images during import.\n• We discussed the success criteria and key performance indicators (KPIs), with the customer agreeing to provide performance and form migration metrics.\n• We also reviewed the priority order of the identified tasks.\n:todo_done: *"}, {"signal_id" : "a2e51b91-c4fe-428c-a52c-58773ca03d4c", "text" : "*\n• We demoed IC to 4point - Eric and Dave. \n• They greatly appreciated it. \n• They want it to work to import/export XDPs for existing customers using Output Service and would like to continue using it.\n• They will now use it and share their feedback.\n• They have 2 prospects who were shown IC on 6.5 and would be further interested to use IC on cloud.\n:todo_done: *"}, {"signal_id" : "1729cc54-2893-44ef-b487-66b1bca67fa5", "text" : "*\n*Meeting Summary*\nWe had a productive discussion regarding the issues NFCU is facing and their use cases. Below are the key discussion points:\n1. *Data Binding Workflow:*\n    ◦ Provided a detailed explanation of the data binding workflow and scenarios for using the data reference option.\n    ◦ Discussed the functionality of @notation and drag-and-drop features in detail.\n    ◦ Identified the need for improved UX to show different data binding options for text boxes and other dynamic fields.\n2. *PDF Preview Issues:*\n    ◦ NFCU reported issues with PDF previews in specific scenarios involving documents with multiple fragments and fields.\n    ◦ Noted the lack of access to NFCU's dev2 environment, which is necessary to resolve the issue.\n    ◦ Requested templates and fragments to investigate the issue further as well.\n3. *Rich Text Editor Misalignment:*\n    ◦ NFCU is experiencing misalignment of text contents, particularly data bindings, when editing using the edit workflow (save the document, go to forms manager, select edit option).\n4. *Conditional New Line in Text Box:*\n    ◦ NFCU has a use case requiring the avoidance of new lines if certain data is not present.\n    ◦ Example scenario: In a text box containing @userfirstname, @usermiddlename, and @userlastname, if @usermiddlename is not present, the generated PDF should not include a new line between @userfirstname and @userlastname.\n:todo_done: *"}, {"signal_id" : "9a76de2d-9005-490b-9ef2-656d94bd2997", "text" : "*\n• Customer discuss about mandatory and option forms.\n• The customer mentioned that, in addition to generating an XDP from the legacy PDF, they also need to create an Adaptive Form.\n•  They mentioned that that binding needs to be performed twice— once in the XDP and again in the Adaptive Form.\n•  Due to certain legal requirements regarding the format of the generated PDFs, they are using XDP to ensure compliance.\n• Publishing Issues: They reported intermittent issues with form publishing, where the updated version doesn’t always reflect on the publish instance, requiring manual unpublish and republish actions. I requested them to share a specific form where this happened; they will provide it when the issue occurs again.\n:todo_done: *"}, {"signal_id" : "30c331f4-e743-4c97-be8a-777a3c513258", "text" : "*\nDiscussed mostly around submissions and capabilities available in core component based forms.\nThere are a few queries, and ask for support for additional capabilities.\n:todo_done: *"}, {"signal_id" : "017715e9-622e-4d9b-bcbd-70f9d0b7727c", "text" : "*\n• 4Point is the implementation partner for the net new customer 4Point. \n• It is first customer for 4Point on Cloud servicer and OSGI side as well. \n• The customer’s use case is data capture using AFs followed by review and approval process and subsequent likely DoR generation.\n• They had general questions around how things work in Forms Cloud Service and the OSGI world, how environments work, etc. \n:todo_done: *"}, {"signal_id" : "11e6a0f8-960f-4fbf-9e93-8f5720fc3adc", "text" : "*\n• The customer was provided with a demo showcasing IC Cloud Editor and its capabilities in comparison to the existing on-premises editors.\n• The customer expressed positive feedback regarding the enhanced user experience and streamlined functionality offered by the cloud editor.\n• The customer requested information regarding the migration strategy for their portfolio of 500-600 letters to the cloud platform. The team provided an overview of the VIP engagement program to facilitate this transition.\n• The customer was asked to explore the new editor and share honest feedback with the team for improvements.\n:todo_done: *"}, {"signal_id" : "3585fff6-2b35-49f8-a8f2-8ec8bdb28b2d", "text" : "*\nSummary of Discussion with NFCU -\nWe had a discussion regarding the challenges NFCU is facing and their specific use cases. Below are the key points discussed:\n1. *PDF Preview Issues*:\n    ◦ NFCU reported issues with PDF previews in scenarios involving documents with multiple fragments and fields.\n    ◦ NFCU will provide access to the dev2 environment, which is necessary to resolve this issue.\n2. *Conditional New Line in Text Box*:\n    ◦ NFCU has a use case requiring the avoidance of new lines if certain data is not present.\n    ◦ Example scenario: In a text box containing @userfirstname, @usermiddlename, and @userlastname, if @usermiddlename is not present, the generated PDF should not include a new line between @userfirstname and @userlastname.\n    ◦ NFCU will provide an existing XDP to better demonstrate this use case.\n3. *FDM-Related Queries for NFCU*:\n    ◦ Storage Data Source: We sought information about the storage data source.\n    ◦ API Details: We inquired about the availability of a Swagger endpoint or file for their REST API. As per current information, they will be using the REST API.\n\n:todo_done: *"}, {"signal_id" : "d41b167a-3c88-47c6-8c0e-7e77ce441570", "text" : "*\nTom Sonntag (TAM) reached out: FirstBank team reached out to me to continue working towards their migration of Forms to CC.\n\nI have requested details on number of forms, and if possible the URLs of these forms. This could be a good opportunity to leverage the migration utility to ease the migration. Tom is checking with the customer and will be sharing the updates soon.\n\nThis is from internal slack discussion - no meeting scheduled yet.\ncc: <@U03BKR6K3R8>\n:todo_done: *"}, {"signal_id" : "4c3f1052-d92a-4e53-9539-fc5b01714898", "text" : "*\nCharles Shwab is an old AEM Forms customer (originally LiveCycle customer -&gt; moved to OSGi). They are using XDP Forms and want to migrate to HTML5 Forms.\n• They are on-prem - 6.5.22\n• 800-900 forms\n• Font issue - is currently a blocker: <https://aemcs-workspace.adobe.com/bot/conversation/fd1a2149-f976-41e0-b135-8bbba0ebc139|E-001631249>\n• *HTML Extension for Caching:* Sudhanshu, Devendra, and Abhishek Kolluru discussed the recent change to cache HTML (.html extension is not coming on 6.5 and was added recently on 6.5) on the cloud service and the possibility of backporting this enhancement. Abhishek emphasized the importance of this feature for their large number of forms and server capacity. <@W6CBB4953> they mentioned about caching implemented and then removed (from last meeting discussion) - due to some issues on mobile - could you provide more details.\n• *Embedding HTML Forms:* Devendra demonstrated how to embed HTML forms in external sites using an iframe and dispatcher settings. Sudhanshu clarified that this method can be applied to any external site.\n• *Static vs Dynamic HTML Forms:* Abhishek Kolluru and Sudhanshu discussed the caching of static HTML forms and the challenges with dynamic forms. Abhishek highlighted the importance of not caching forms with query parameters and the need for static forms to be cached.\n• *Font Issue on Mac:* Abhishek Kolluru raised a font issue with HTML5 forms on Mac, which works fine on Windows. Devendra suggested creating a custom CSS profile to address the issue. Sudhanshu requested the support ticket ID to review and confirm the issue.\n• *JSON Payload for Prefilled Forms:* Abhishek Kolluru explained their process of using JSON payloads to prefill forms and the challenges faced with CSS and JS references in the HTML forms (_currently relative path - need absolute path_). Sudhanshu noted the need to identify and document the steps to address this issue.\n\n:todo_done: *"}, {"signal_id" : "0c11a622-eee6-40ea-88c8-e171377ff087", "text" : "*\nPrep meeting with Busch Group and eggs Unimedia to discuss the agenda for the demo scheduled on 13th May.\n\nPrimary customer concern is around simplification of templates.  They have 185 templates in all and they operate in many countries. Adapting a template to a small change in one region affects elsewhere.\n\nReusable fragments and multi-language localization are definite areas of interest. Can also use the occasion to showcase the new Composer.\n\nAttendees from customer side will be mostly IT, the commercial aspect will be followed up later.\n:todo_done: *"}, {"signal_id" : "497e79ae-f742-415e-89b6-b21790d7d353", "text" : "*\n*NFCU*: Sharmila, Sreedhar, Aishwarya\nCurrent Communication Journey (DSC) that is live is a failover letter generation capability where a scheduled batch is run twice a day which picks up the failed entries one by one and generated PDF.\n\nMany other departments are interested in Forms Communication and one department (Standardization team) is very much focused on Quadient tool and Sharmila and team might need our help in demoing our product to that team if required. (Post May end, when we deliver MVP committed features)\n\nSharmila mentioned about New usecase, where they want to create a 4 fields of independent AF (Credit Card disclosure Form - unauthenticated form)\n• last 4 Credit card number\n• Re-enter\n• Access No\n• Confirm\n• Submit -&gt; Call Muelsoft API - Pega Platform\nTheir Program is internal where the URL is whitelisted only within NFCU, but for this form they want a Public URL.\nThey wanted to understand any Risk for this usecase.\nMentioned that its very straight forward usecase and we can have a POC to fizzle out any concerns and NFCU should check with their Security team on how to allow an internal specific URL publicly.\n:todo_done: *"}, {"signal_id" : "06417b05-6043-46fd-9dc3-4a407b1ca0c3", "text" : "*\nSummary of Discussion with NFCU\nWe had a brief discussion with NFCU regarding the challenges they are currently facing and their specific use cases. The key points from the conversation are outlined below:\n1. *PDF Preview Issues*\n    ◦ NFCU has yet to provide access to their DEV2 environment, which is essential for further investigation and resolution of the issue.\n    ◦ Alternatively, they may share the relevant XDP file via a support ticket to facilitate further analysis.\n2. *Conditional New Line in Text Box*\n    ◦ NFCU will share an existing XDP file via a support ticket to better illustrate this use case.\n3. *Template as Reference Support*\n    ◦ NFCU is currently exploring the use of fragments on their end to determine if it addresses their requirements.\n    ◦ We noted that using templates as references may not fully resolve their use case, as users would still need to review all referenced documents individually to verify layout consistency.\n\n:todo_done: *"}, {"signal_id" : "1262384d-9ae0-4ede-87e5-afc30f9f6e61", "text" : "*\nProposal meeting to Busch Group in response to their RfP for Communications.\n\nThe meeting kicked off with Nick Maerlender setting the context and briefly introducing the Adobe team. He then handed over to Dominik Emmert who presented the overall AEM and Forms story + capabilities.\n\nThis was followed by 6 mini-demos from <@W4R5WN6LR> primarily showcasing template authoring via Desktop Designer, each with a particular theme (fragments, localization via data/scripting etc.) mapping to their requirements and (inferred) pain-points shared earlier. After partly presenting the 7th demo, handed over to <@WE163TH43> who focused on the authoring experience in Cloud Designer by demo'ing live the creation of a Communication template and document with fragments. <@W010NNJV7S8> then wrapped up the Adobe side of things by sharing the roadmap and exciting things ahead for Forms and Communications.\n\nAt this point, approximately 10 minutes remained out of the 90 allotted for the meeting, when Martin Grimm from eggs Unimedia began explaining their development strategy as a 15+ yr. old Adobe partner experience, primarily in AEM Forms since the LiveCycle days. There were pointed questions about integration with SAP, to which both Martin and <@W9QMZFR39> replied.\n\nWe then ran out of time and the Busch attendees could not extend so it was agreed that Nick would connect again with them by the end of this week to discuss commericals and gather consolidated feedback.\n:todo_done: *"}, {"signal_id" : "6d5af81a-e1c5-4294-a6e9-1670f8df1b2c", "text" : "*\nFolks for ACS team also attended this meet.\n\n- The customer was provided with a demo showcasing IC Cloud Editor and its capabilities in comparison to the existing on-premises editors.\n- The customer expressed positive feedback regarding the enhanced user experience and streamlined functionality offered by the cloud editor.\n- The customer requested information regarding the following:\n\t- Support for FDM/JSON data - Team informed that it is in development and will be available soon.\n\t- Availability of Agent UI on cloud - Team informed that it is planned for next phases.\n\t- Migration of (100s of) on-premise 6.5 ICs - Team informed about the VIP engagement to facilitate the migration.\n\t- Availability of PDF generation APIs corresponding to IC - Team provided a brief overview of the render API.\n\t- Nested fragments use-case - Initial analysis of the collateral revealed that nested fragments (Document Fragments inside Layout Fragments) were created due to lack of FDM support in designer and layout support in IC Editor. This requires further evaluation from both teams.\n:todo_done: *"}, {"signal_id" : "940c8ce1-365e-4ea0-9e67-2081c360ca85", "text" : "*\n*Meeting notes* _(AI generated - updated for corrections/details)_\n_Attendees included folks from IRS (None from Accenture)_\n• Ande Vara Prasada Rao\n• Gower Andrew R\n*Details:*\n• *Adaptive Form Conversion Tool Demonstration:* Shivam demonstrated the adaptive form conversion tool, explaining the process of converting forms, selecting directories, and scheduling jobs. They highlighted performance issues and showed a pre-converted form.\n    ◦ *Custom Components and Conversion Limitations:* ~Shivam and Sudhanshu discussed the challenges with custom components created by IRS, which the utility cannot convert due to lack of information~. Sudhanshu mentioned that the utility is available on GitHub and can be extended to include custom component transformations.\n    ◦ *Open Source Utility and Compatibility:* Sudhanshu and Ande clarified that the utility is open source, supports on-premises installations, and requires minor changes in build steps for different setups _(we shared steps to run the utility on a 6.5 setup)._\n    ◦ *Schema Conversion and Binding:* Shivam explained the need to convert XML schemas to JSON schemas for AF2, and how the utility handles binding automatically. Ande inquired about automation tools for schema conversion (_we clarifies that there is no OOTB tool/API to convert XML Schema to JSON Schema - but there are multiple tools in public domains - and it would require verification of the generated output_).\n    ◦ *Fragment Conversion and Custom Libraries:* Shivam highlighted the need to manually convert fragments and update references. ~They also mentioned issues with custom libraries and functions not supported in AF2.~\n    ◦ *Visual Rule Editor and Business Rules:* Sudhanshu discussed the need to redefine business rules in AF2, emphasizing improvements in the visual rule editor for easier rule definition _(clarified that the rules need to be re-defined after conversion)._\n    ◦ _*Feedback -* Vara (IRS) appreciated the tool, and found it quite useful. He mentioned that it would save a lot of effort during migration._\n• *Performance Comparison (FF vs CC):* Ande requested a performance comparison before and after conversion. Shivam showed that the performance more than doubled after conversion (_Lighthouse score doubled - from ~ 36 to 75. Low score due to large number of fields in the form)._\n    ◦ *Form Conversion Process:* Shivam demonstrated the form conversion process again, explaining how to select source and target folders, and schedule jobs. Ande asked about converting multiple forms at once (_which is supported_)\n        ▪︎ *Error Logs and Custom Logs:* Shivam and Sudhanshu discussed error logs and the possibility of configuring custom logs for better tracking of conversion issues.\n• *Local Conversion vs. Cloud API:* Ande and Sudhanshu compared the local conversion tool with the cloud-based *Afcs*, highlighting the differences in processing and security.\n    ◦ *Adobe Support for Conversion Tool:* Ande confirmed that Adobe supports the conversion tool and can provide assistance with any issues during the conversion process.\n        ▪︎ Clarified that the tools are for different purpose\n        ▪︎ Concern - Migration tool does not support taking Template/Theme during conversion - as AFCS does\n        ▪︎ Clarified that the migration tool is supported - and Adobe would help investigate/resolve any issue they report with the tool.\n• *Save Draft Functionality:* Ande raised concerns about the lack of save draft functionality in core components, which is critical for IRS use cases. Sudhanshu acknowledged the issue and shared that he would discuss internally and share an update in the next call.\n:todo_done: *"}, {"signal_id" : "780a31a7-4ab9-45be-aa47-504aafb9847e", "text" : "*\nGenerated by AI.\n*IRS attendees* (_there were more attendees from IRS - but active participants were_):\n• JP Terry\n• Ande Vara Prasada Rao\n• Gower Andrew R\n*Meeting notes:*\n• *Automated Forms Conversion Service Demo:*\n    ◦ *Automated Forms Conversion Service Configuration:* Gaurav demonstrated the configuration of the automated forms conversion service on a local setup, including adding developers, creating projects, and configuring the service on the AM instance.\n        ▪︎ *Service Configuration:* Gaurav explained that when the Automated Forms Conversion (AFC) service is provisioned for an organization, an administrator is assigned to add developers responsible for configuring the service on the AM instance. The administrator uses the admin console to add developers to the product profile.\n        ▪︎ *Developer Console:* After being added, developers need to create a project in the developer console, add an API, and configure server-to-server authentication. Gaurav demonstrated creating a new project and selecting the automated forms conversion API.\n        ▪︎ *Client ID and Secret:* Gaurav showed that after configuring the API, developers receive a client ID, client secret, scopes, and organization ID. These details are used to configure the AM local server by going to the security settings and Adobe IMS configurations.\n        ▪︎ *Health Check:* Gaurav performed a health check to ensure the configuration was correct, confirming successful token retrieval and authentication for the automated forms conversion service.\n    ◦ *Cloud Configuration for Automated Forms Conversion:* Gaurav explained the process of creating a cloud configuration for the automated forms conversion service, including selecting templates and themes for the converted forms.\n        ▪︎ *Cloud Services:* Gaurav navigated to the cloud services section to create a cloud configuration for the automated forms conversion service. He demonstrated selecting a contribution folder and naming the configuration.\n        ▪︎ *Endpoint and Template:* Gaurav explained that the endpoint for accessing the service and the template type (foundation-based or core component-based) are selected during the configuration. He showed how to choose a template and a theme for the converted form.\n        ▪︎ *Configuration Example:* Gaurav provided examples of configurations for both V2 (core component-based) and foundation-based templates, showing the IMS and cloud configurations already set up.\n    ◦ *Conversion of PDF to Adaptive Forms:* Gaurav showed how to upload a PDF and start the automated conversion process, resulting in an adaptive form with the same fields and structure as the original PDF.\n        ▪︎ *PDF Upload:* Gaurav demonstrated uploading a PDF document with fields such as date, reason, total amount, and text areas. He explained that the document is uploaded to the AM instance.\n        ▪︎ *Start Conversion:* Gaurav showed how to select the uploaded PDF, choose the desired configuration (V1 or V2), and start the automated conversion process. The configurations are prefilled with the selected template and theme, but can be overridden if needed.\n        ▪︎ *Conversion Process:* Gaurav explained that the conversion process involves sending a request to the AI/ML service, which processes the images and creates an adaptive form. He showed the converted output, highlighting that the fields and structure matched the original PDF.\n        ▪︎ *Foundation and Core Components:* Gaurav demonstrated the converted outputs for both foundation-based and core component-based forms, showing that the fields were correctly identified and configured in the adaptive forms.\n    ◦ *AI and Machine Learning in Forms Conversion:* Ande and Gaurav discussed the role of AI and machine learning in identifying widgets and fields in the PDF during the conversion process.\n        ▪︎ *AI Role:* Gaurav explained that AI helps identify widgets and fields in the PDF, such as captions and input fields, by analyzing the structure of the form. The AI models group related captions and fields to create adaptive form fields.\n        ▪︎ *Field Grouping:* Gaurav provided an example where the AI grouped a caption and input field to create a field for capturing the insured name. He also explained how sections and panels are identified and extracted from the PDF.\n        ▪︎ *Vision Models:* Gaurav mentioned that vision models and machine learning models are used to identify the structure, fields, sections, and captions in the PDF, enabling the creation of adaptive forms from straightforward PDF screenshots.\n    ◦ *Issues with Core Component Template:* Terry raised an issue with the core component template failing to convert forms, and Gaurav suggested providing the latest build and enabling a feature toggle to resolve the issue.\n        ▪︎ *Issue Raised:* Terry reported that while the foundation component template worked fine, the core component template failed to convert forms, displaying an error message suggesting retrying the conversion or contacting Adobe support.\n        ▪︎ *Latest Build:* Gaurav acknowledged the issue and suggested that the latest build and enabling a feature toggle could resolve the problem. He mentioned that the core component form conversion support was recently added.\n        ▪︎ *Configuration Steps:* Terry asked if any additional steps were needed on the server. Gaurav confirmed that once the latest code and feature toggle are enabled, creating a new configuration with the core component template should work.\n        ▪︎ *Service Pack:* Terry inquired about the required service pack version. Gaurav promised to confirm whether a new service pack or the existing one (6.5.22 or 6.5.23) would suffice and share the necessary details.\n    ◦ *Custom Components and Meta Model:* Gaurav explained how to use the meta model to map custom components to specific fields during the forms conversion process.\n        ▪︎ *Meta Model:* Gaurav introduced the concept of the meta model, which allows extending out-of-the-box configurations by mapping custom components to specific fields identified in the PDF during the conversion process.\n        ▪︎ *Custom Component Mapping:* Gaurav demonstrated how to map a custom component, such as an SSN field, by providing a mapping in a JSON file. This mapping ensures that the custom component is used instead of the default component during conversion.\n        ▪︎ *Configuration Path:* Gaurav showed that the custom meta model can be uploaded to the AM instance, and the path to the JSON file can be specified in the cloud configuration to apply the custom mappings during conversion.\n        ▪︎ *Form Level Validations:* Ande asked about including form-level validations in the meta model. Gaurav confirmed that properties such as required fields, default values, and validation rules can be added to the JSON file and applied during conversion.\n    ◦ *Security Concerns with Cloud-Based Conversion:* Ande asked about security concerns with cloud-based conversion, and Anurag assured that the communication is secure and within the IRS authenticated context.\n    ◦ *Popularity of Automated Forms Conversion Service:* Ande inquired about the popularity of the service, and Anurag confirmed that several customers have been using it since its release in 2017-2018.\n• *Generative AI Demo:* Gaurav demonstrated the capabilities of the Form Experience Builder, a conversational assistant that helps in authoring and creating form experiences using generative AI.\n    ◦ *Form Creation:* Gaurav demonstrated the Form Experience Builder, which uses generative AI to create forms based on user-provided intents. He showed how to enter an intent, select a template and theme, and create a form.\n    ◦ *Assistant Interface:* Gaurav explained the assistant interface, which provides commands for creating and updating forms. He demonstrated adding a panel, updating the layout, and creating business logic using the assistant.\n    ◦ *Rule Creation:* Gaurav showed how to create a rule for setting an email address based on the first and last names. The assistant generated the rule, and Gaurav confirmed its functionality in the preview mode.\n• *Cloud Sandbox for Generative AI:* Arun suggested setting up a cloud sandbox for the IRS team to use the generative AI technology for creating forms, as it is currently only available in the cloud version.\n:todo_done: *"}, {"signal_id" : "bc44b29b-adbc-452c-a6d3-bc89d4b7ddb9", "text" : "*\n• Presented two major use cases for form pre-filling(from user entered data and from incoming persisted Json) and the current approach involving manual conversion and data binding, highlighting scalability issues. We got confirmation from the customer about pain points and workflow.\n• They discussed the challenges of converting forms from Word documents to AEM forms, emphasizing the time-consuming nature of the process. They also mentioned that incoming Form can be in word format also.\n• Demonstrated AFCS with its current capabilities and how these can be leveraged to address certain use cases in the existing implementation. Specifically, we showcased the flow: Acroform PDF → AF → Auto DoR.\n• Demonstrated the Forms Experience Builder, showcasing its ability to create and modify forms using natural language input and images.\n• We also demonstrated a PoC where Forms Experience Builder analyzes AFCS-converted Adaptive Forms for quality issues, aiming to enhance the accuracy of automated conversions. This is in Dev and we are working on it for improving its quality.\n:todo_done: *"}, {"signal_id" : "f6d6c41c-097a-4d71-82db-16a8c76fdbd3", "text" : "*\n• NFCU talked about expanding the adoption of IC Editor internally, subject to maturity of the product.\n• They have 2 projects coming up spanning across other departments in NFCU in the next quarter, that would start in mid June\n• The major requirement of the 1st project data binding from APIs\n• The requirements for the 2nd project is still being figured out, but based on the rudimentary details they currently have, it seems to make a good fit for Associate UI\n:todo_done: *"}, {"signal_id" : "45969a1b-33df-4351-9a1e-07d96f271892", "text" : "*\n*Discussion Summary*\nWe had a brief discussion covering the following key issues:\n• *PDF Preview Issue:* NFCU will provide access to their DEV2 environment to support further investigation and resolution.\n• *Non-IC Issue:* Themes are not loading correctly in the App Framework (AF) across consecutive updates. We have advised logging a support ticket to address this behavior.\n• *Release Update:* NFCU has requested a status update once the release is completed at the end of May.\ncc: <@WQWCBV6NN> <@W4R5LUPK3> <@W9QMZFR39>\n:todo_done: *"}, {"signal_id" : "981f4454-81ab-40cc-a3eb-521060096eb0", "text" : "*\n*Issues they reported:*\n    ◦ In order for this to work I need to add Access-Control-Allow-Origin header to <https://main--forms--ociostateofnebraska.aem.live/> which is fine, and I am able to do this. However, it seems that once the header is present on this domain the Universal Editor stops working. The paths it tries to pull block scripts from are all adjusted/broken. I can show this on the call today.\n        ▪︎ _Resolved in the meeting._\n    ◦ This form sends an email. The email template editor is a rich text editor, and the email is plain text, so the raw html is in the email body. When trying to use the external template field to point to a template I put in the DAM, it does not work, and I get an empty email body.\n        ▪︎ _Resolved within 30 mins of the meeting_ - luckily we had the feature for CC in EA - and Ravi helped enable on their EDS environment by updating their dialog quickly - <https://github.com/OCIOStateOfNebraska/stateofnebraska-aem/pull/84>\n    ◦ If we have time, I’d like to discuss the “persist to spreadsheet” form action to see if it is viable for a new requirement.\n        ▪︎ They wanted to submit form to a excel in different Org which is not supported - <@W4R5Y3YHX> please correct me if I got this wrong :sweat_smile:\n        ▪︎ They decided not to try to do excel at launch. But we are clear on how if and when they choose to do it _*(got this latest update from Jeff today)*_\n    ◦ _*Open item:*_ They have GoogleReCaptcha v2 license and EDS supports v3 - customer thought they needed a Google enterprise account to use v3  _*(got this latest update from Jeff today)*_ - I don't they that is the case - <@U0213T59LMN> are you aware?\n<@W012PACNGHJ> <@U02P8T2L0R5> <@W4R5Y3YHX> please share/update in case I missed something.\n\nPS: The customer dev was really happy with the meeting - and especially appreciated the fact that we resolved 2 of the issues within the meeting.\n:todo_done: *"}, {"signal_id" : "ff88e308-8936-4fb1-9e9e-0dca5544a715", "text" : "*\nProvided a demonstration of the fixes implemented in SP23 within AEM Designer. The issues addressed during the session included:\n<https://jira.corp.adobe.com/browse/LC-3921997>\n<https://jira.corp.adobe.com/browse/LC-3922619>\n<https://jira.corp.adobe.com/browse/LC-3922633>\n\nWells Fargo is looking forward to the availability of the SP23 release.\n:todo_done: *"}, {"signal_id" : "023eb1e1-c371-4aa0-9e53-855ad42f86a3", "text" : "*\nMOM of today's call with GM\n• The 403 issue for the forms is resolved , it was related to allowing the edge domain in the referrer filters of publish. Now submission is getting processed to aem publish.\n• There is an issue in their author instance where the Universal Editor content tree is not listing down the components inside AdaptiveForm Container and hence they are not able to edit anything. I checked the logs and initially there was an NPE because of component-models file was incorrect. I got that resolved. Now that NPE is gone but still content tree is not rendering. We need to resolve this on priority. \ncc:- <@W012PACNGHJ>, <@U01G51VDXB8>, <@U0213T59LMN>, <@W4RSW3ECC>\n:todo_done: *"}, {"signal_id" : "fda9ca04-58a2-4269-871c-464a1d4e127d", "text" : "*\n• NFCU had a requirement where a 4 field form needs to submit to a Mulesoft API. During the call they shared that the requirement is that API is authenticated. <@U03Q109GQMT> quickly demonstrated the form and also showcased the API integration tool which can be used as Invoke Service. This feature has been enabled on their dev2 environment and they would be testing it. Sharmila (NFCU) emphasised the criticality and wants to take live this form by mid june.\n• NFCU also shared requirement of converting PDF to HTML and it would be used in multiple sites. They want to ensure that user has scrolled to bottom of all the Terms and Conditions then provide consent and Submit the Form. We showcased PDF link and PDF viewer component but they want HTML version of PDF only. We mentioned that future of IC where both Print and Web channel are available would be helpful, but currently that have lots of PDFs which they want to show as HTML in AF.\n• Also they have requirement to print empty AF\n• Another requirement is to have unmapped data to be part of Submit. Hidden fields is not an option due to security concerns. This feature is already being worked upon for HDFC and will enable for NFCU as well.\n• Good news Sharmila shared that Admin Services department handling logistics and having 3000 Letters who were inclined towards Quadient have now been convinced with AEM Forms, based on future of IC and their current custom fragment implementation.\n• Highlighted to NFCU team, there is a delay in IC due to Architecture level changes, and ETA we are targeting is 12th June.\nKudos to <@U03Q109GQMT> for quickly preparing the demo and showcasing Authoring of various Rules/Validation. This provided confidence to NFCU team that we are equally invested in their go live.\n:todo_done: *"}, {"signal_id" : "414ca0b1-f039-422b-a9c8-2d3720498987", "text" : "*\n*Forms Conversion Challenges:* Naveen (LPL) discussed the challenges faced in converting forms into the AEM side, mentioning that previous attempts either failed or did not meet the standard. They sought assistance from the team to resolve these issues. Also enabling Adobe AI capabilities, specifically for editing adaptive forms.\n*Forms Conversion Demonstration:* <@W4R4VBWQG> demonstrated the conversion of forms from afcs to adaptive form v2, showing the workflow and the output PDF generated with filled information. They addressed issues with headers and repeated fields.\n\n*Forms Conversion Milestones:* We offered a VIP offering to them and asked for their commitment , go LIVE dates , internal milestones , success criteria and number of go LIVE forms.\n\n*JSON Structure Support:* Naveen Sharma requested support for JSON structure in form binding, as it would save time and increase API performance. They discussed the challenges faced in converting forms and how Gen AI could help overcome them.\n\n*Implementation Partner:* Naveen Sharma mentioned that their implementation partner, Proficient, was helping with migrating user forms into AM forms. They discussed the timeline for going live with the forms(700-800forms), targeting July-August.\n\n*Optimised Web Forms:* We discussed the possibility of optimising web forms by converting textual data into terms and conditions. They considered the business requirements and user experience on the web.\n.\n*Forms Sharing Process:* Naveen Sharma asked about the best way to share a large number of PDFs for conversion. We suggested using a sandbox environment or sharing through email or Slack or Teams, and creating categories for forms to target.\n:todo_done: *"}, {"signal_id" : "7c604027-fdb8-4ec8-bd56-7fe90ce6c850", "text" : "*\n*Questions for IRS/AF meeting*\n1. Are they using same UI for listing both AF1 and AF2 forms? *Yes (Not applicable as they are not using lister component)*\n2. Are they using draft and submission lister for submissions also? *Do not use this component - No use-case now..*\n3. If same UI, then recommendation is to use Listing (V1) else Listing (V2) would require styling changes  - *Not applicable*\n4. Local SDK testing for customisations (which we can provide by Monday) - *Need to share Local SDK with Accenture. Accenture to share the customization code,*\n5. \n    a. Postgress storage ( can we get the impl code, to assit you better for converter implementation)\n    b. Large Attachment support ( Custom Core component)\n    c. Multi - Signer\n6. Any other customisations that have done for Save As Draft/ Listing? - *Yes - they are using a custom component.*\n7. HF on SP22 or SP23? They are on SP21 - *No plans for 23 right now.. Accenture would confirm. - Will not have clarity by Tuesday - will need more time. Currently they are on SP21*\n:todo_done: *"}, {"signal_id" : "86121a51-20d1-4818-8237-bcb96f1cbe68", "text" : "*\nGenerated by AI. Make sure to check for accuracy.\nMeeting notes:\n• *Adaptive Forms Creation:* Ellen explained the process of creating adaptive forms, highlighting the need to support multiple languages and brands for KBC websites. They discussed the challenges faced due to the differences in content and the advantages of using core components for translation and embedding within the KBC mobile app.\n    ◦ *Adaptive Forms Process:* Ellen described the process of creating adaptive forms, which involves using the usual method of going into forms and documents to create sites. These forms are used across KBC brands and websites, supporting four languages: Dutch, French, English, and German.\n    ◦ *Language and Brand Support:* Ellen highlighted the need to support multiple brands and languages for KBC websites. KBC has three sub-brands: KBC for Dutch-speaking audiences, CBC for French-speaking audiences, and KBC Brussels. Each form shares functionality but may have slight content differences.\n    ◦ *Core Components Advantages:* Ellen explained the advantages of using core components, which include the ability to use translation features and embed forms within the KBC mobile app. This reduces the workload for authors, as translation partners handle translations, eliminating the need for manual input.\n• *Document of Record Requirement:* Ellen detailed the requirement for a document of record in adaptive forms, which is crucial for pre-filling data and processing it through the KBC workflow. They mentioned the current limitation of embedding adaptive forms within websites and the need to migrate forms from foundation components to core components.\n    ◦ *Document of Record:* Ellen explained that the document of record is essential for pre-filling data and processing it through the KBC workflow. This document is used for GDPR and legal purposes, ensuring records are maintained for submissions.\n    ◦ *Embedding Limitation:* Ellen mentioned the limitation of embedding adaptive forms within websites, which currently does not support the document of record functionality. This is a critical requirement for migrating forms from foundation components to core components.\n• *Custom Development for Document of Record:* Ellen and Tim discussed the custom development they implemented to add a document of record to the adaptive form container. They highlighted the need for this functionality to be included in the Adobe Root code to avoid future issues and reduce workload.\n    ◦ *Custom Development:* Ellen and Tim described the custom development added to the adaptive form container to include the document of record functionality. This development was necessary due to the missing feature in the current setup.\n    ◦ *Adobe Root Code:* They emphasised the need for this functionality to be included in the Adobe Root code to prevent future issues and reduce the workload for their team.\n• *Current Status and Future Needs:* Anurag and Tim clarified that the custom development for the document of record is not fully functional and needs to be more extensive. They discussed the need for both the document of record configuration and schema selection to be available out-of-the-box.\n    ◦ *Current Functionality:* Anurag and Tim clarified that the current custom development for the document of record is only partially functional and requires further development to meet their needs fully.\n    ◦ *Out-of-the-Box Needs:* They discussed the necessity for both the document of record configuration and schema selection to be available out-of-the-box to streamline their processes and avoid custom development.\n• *Form and Document of Record Specifics:* Sudhanshu and Ellen discussed the specifics of the document of record for different logins and locales. They explained the need to configure the document of record properties for each locale and the challenges faced due to the current inability to select it.\n    ◦ *Locale-Specific Configuration:* Sudhanshu and Ellen explained that the document of record needs to be configured for each locale, with properties specific to each language and brand variant.\n    ◦ *Current Challenges:* They highlighted the challenge of not being able to select the document of record at the moment, which is a significant issue for their workflow.\n• *Form Submission and Page Configuration:* Ellen and Anurag clarified that there is typically one form per page with one submit action. They discussed the potential confusion for end users if multiple forms were present on a single page and the preference for a single submit action.\n• *Timeline and Impact:* Ellen and Anurag discussed the timeline for implementing the required functionality, with Ellen mentioning the urgency due to ongoing projects. Anurag assured that they would provide an ETA by Friday after internal analysis and planning.\n    ◦ *Urgency of Implementation:* Ellen emphasised the urgency of implementing the required functionality due to ongoing projects and the need to maintain momentum in converting components to core components.\n    ◦ *ETA Assurance:* Anurag assured Ellen that they would provide an ETA by Friday after conducting internal analysis and planning to determine the feasibility and timeline for the required development.\n• *Future Plans and Conversion:* Ellen explained the goal of converting existing forms and building new ones using core components to reduce workload on KBC local offices. They mentioned the planned timeline for this conversion and the importance of providing the required functionality to meet their targets.\n    ◦ *Conversion Goals:* Ellen outlined the goal of converting existing forms to core components and building new ones using the same technology. This conversion aims to reduce the workload on KBC local offices by automating processes currently done manually.\n    ◦ *Planned Timeline:* Ellen mentioned the _*planned timeline for this conversion, aiming to complete it within one to two months. The urgency is driven by the need to meet targets and improve efficiency.*_\n• *Next Steps:* Anurag assured Ellen and Tim that they would conduct internal analysis and provide an ETA for the required functionality by Friday. _*They emphasised the importance of addressing the product gap and unblocking the team as soon as possible.*_\nFollow-up tasks:\n• *Document of Record Functionality:* Conduct internal POC and discussions to assess the effort required to implement the document of record functionality for adaptive forms. (Anurag)\n• *Timeline Assessment:* Check with the product owner to determine the feasible timeline for implementing the document of record functionality. (Ellen)\n:todo_done: *"}, {"signal_id" : "f9c44d65-f58b-42c2-95c0-5e961264d4a1", "text" : "*\n*Meeting notes:*\n• *Edge Delivery Services Training:* Daniel inquired about the team's understanding of Edge Delivery Services and whether there are any learning paths available. Tom confirmed that a preliminary coaching session has been conducted and a more advanced session is in the pipeline.\n    ◦ *Preliminary Coaching:* Tom confirmed that the team has already had one preliminary 101 coaching session on edge delivery services, which was not specific to forms.\n    ◦ *Advanced Session:* Tom mentioned that a more advanced session on edge delivery services is currently in the pipeline and will be conducted soon.\n• *Forms and Marketing Involvement:* Daniel discussed the involvement of the marketing team in form sessions, suggesting that they should be included in basic form sessions for landing pages. Glorianne agreed that forms might be more advanced for marketing, and it will be managed by their team.\n    ◦ *Marketing Inclusion:* Daniel suggested that the marketing team should be included in basic form sessions for landing pages, as they might need to add basic forms to landing pages.\n    ◦ *Advanced Forms:* Glorianne agreed that forms might be more advanced for the marketing team and stated that their team would manage the more advanced form sessions.\n• *Core Components Migration:* Sudhanshu questioned Felix and Fabian about the necessity of migrating to core components if their existing foundation forms are working fine. Felix and Fabian agreed that there is no pressing need to migrate unless there are critical errors.\n    ◦ *Migration Necessity:* Anurag asked if there was a pressing need to migrate to core components if the existing foundation forms were working fine. Felix and Fabian agreed that there was no immediate need to migrate unless there were critical errors.\n    ◦ *Support Tickets:* Anurag mentioned that if there were any support tickets raised, they could address those issues without needing to migrate to core components.\n    ◦ *Future Considerations:* Daniel added that while there was no current need to migrate, they should consider edge delivery services for new forms and pages.\n• *Financial Core Migration:* Daniel asked Felix about the migration of the financial core to cloud services. Felix confirmed that the migration has already happened, but they do not have Azure services like Azure storage or Azure SQL yet.\n    ◦ *Migration Status:* Felix confirmed that the financial core migration to cloud services has already been completed.\n    ◦ *Azure Services:* Felix mentioned that they do not yet have Azure services like Azure storage or Azure SQL, but there are plans to integrate these services in the coming months.\n• *Sensitive Data Automation:* Daniel proposed automating the process of capturing sensitive data from prospects using progressive forms and integrating with cloud services. Felix explained that they are looking into connecting foundation components to Azure storage or Salesforce.\n    ◦ *Current Process:* Daniel described the current process of capturing sensitive data from prospects, which involves generating an Excel file and manually calling each lead to capture additional data.\n    ◦ *Proposed Automation:* Daniel proposed using progressive forms with AEM forms to automate the data capture process and integrate with a system that can securely store sensitive data.\n    ◦ *Integration Plans:* Felix explained that they are exploring ways to connect foundation components to Azure storage or Salesforce to facilitate the automation and secure storage of sensitive data.\n• *Improving Site Performance:* Daniel emphasized the need to improve site performance and suggested using Edge Delivery Services for new sites. Felix proposed using a new landing page project to build and test Edge Delivery Services.\n    ◦ *Performance Emphasis:* Daniel stressed the importance of improving site performance and suggested that new sites should use Edge Delivery Services to achieve better performance ratings.\n    ◦ *Landing Page Project:* Felix proposed using a new landing page project with its own domain as a test case for building and implementing Edge Delivery Services.\n• *Migrating Drupal Site:* Daniel and Felix discussed migrating a new site from Drupal to Edge Delivery Services. Anurag suggested getting in touch with the AEM sites product management team for assistance.\n    ◦ *Migration Discussion:* Daniel and Felix discussed the plan to migrate a new site, \"Uno con El Ambiente,\" from Drupal to Edge Delivery Services: <https://www.unoconelambiente.com/>\n    ◦ *Product Management Assistance:* Anurag suggested contacting the AEM sites product management team, specifically Cedric Huesler or Gabriel, for assistance with the migration process.\n• *Creating Forms with Universal Editor:* Anurag demonstrated how to create forms using the Universal Editor in Edge Delivery Services, highlighting its ease of use and capabilities like generative AI for form creation.\n    ◦ *Universal Editor:* Anurag demonstrated the Universal Editor interface in Edge Delivery Services, showing how to create forms within a page using a simple drag-and-drop method.\n    ◦ *Generative AI:* Anurag highlighted the generative AI capabilities that allow users to create forms by expressing their intent in plain English, which the AI then translates into form fields and configurations.\n    ◦ *Form Creation:* Anurag showed how to add various components to the form, configure fields, and set up submission endpoints, emphasizing the ease of use and flexibility of the Universal Editor.\n• *GitHub Requirement for Edge Delivery:* Fabian inquired about the necessity of hosting code on GitHub for Edge Delivery Services. Sudhanshu confirmed that GitHub is required and will reconfirm if GitHub Enterprise is supported.\n    ◦ Relevant doc: <https://www.aem.live/docs/faq#:~:text=Does%20Edge%20Delivery%20Services%20support%20private%20GitHub%20repositories?,be%20installed%20on%20the%20repository>. <@W4RU4N66R> could you review and confirm. cc: <@W4R4S9FS4> \n\n:todo_done: *"}, {"signal_id" : "24c41b8f-8f6b-4b9b-a3ee-1527108b0126", "text" : "*\nCodePA raised an issue that below issues were critical and blocking development of some of their new forms:\n1. Scribble signature with DoR + Accessibility fixes\n2. Delete operation for files in SharePoint Doc\nThe team had been working on some of the additional features reported by them, and we tried to include the below features fixes - to get early feedback. The plan is to provide a buddy build to them to verify with localSDK - before creating a private build. We want to provide a private build - as waiting till July will impact development of new forms.\n\nCurrently we are targeting the below changes in the build (subject to build/validation next week):\n1. Scribble signature with DoR + Accessibility fixes (FPR)\n2. Date Time input component (FPR)\n3. Malicious file detection - server side mime-type detection (FPR)\n4. Option to exclude hidden fields from DoR (FPR)\n5. Excluding disabled fields from DoR (supporting rules to identify the disabled fields at runtime) (Bug)\n6. Enter key not working in multi-line TextInput field (Bug)\n7. Rules in nested repeatable panel  (FPR)\n8. Delete operation for files in SharePoint Doc (Story)\n:todo_done: *"}, {"signal_id" : "e9ee1c0d-8dc2-4d92-8b8e-1008fd0049bf", "text" : "*\nCS customer interested in following capabilities:\n1. Exp Builder\n2. Multi-modal\n3. Optimizer\n<@W4R4S9FS4> showcased Exp Builder and Multi-modal capabilities.\nThey mentioned CASE #E001266661 is troubling with preview. Product team to check.\n\n1. Bill enquired if Ex Builder can reuse fragments. We told it is in works.\n2. Bill enquired if adding the chat button/conversational interface is an authoring activity or dev work required. We explained it is targeted to be authoring component/config unless custom requirements from them for components, styling etc.\n\n:todo_done: *"}, {"signal_id" : "e984e18a-0304-4ecf-a8ee-2d5eac957362", "text" : "*\nIn multiple meetings with NFCU, engineering, we provided option for their requirement of calling 2 Authenticated API and custom payload data.\n1. Invoke Service - API Integration with Variable and Dispatch envent\n2. FDM - Data Source integration with Authenticated Rest endpoint and pre-processor fucntion\nBut it seems NFCU went ahead with custom implementation, where in AF form submits to MuleSoft API and rest is taken care at their intermediatory layer.\nWe highlighted to NFCU that this requirement was possible through OOTB implementation and they would consider it for other Forms.\n\n<@U0213T59LMN> - Do we have an sample video showcasing FDM with Authenticated Rest endpoint + Pre-processor functionality? Couldnt find any public documentation related to FDM Pre-processor.\n\nPost 17th June, NFCU is looking for IC Editor implementation and we would need to update their Dev envs. Mentioned that currently its EA and we need to deliver it via private release, which later would be available publicly.\n\nAlso need to explore their requirement of showcasing PDF to HTML, there are 3 options\n1. Show as PDF link with consent checkbox ( demo showcased)\n2. Display PDF in the same tab ( Demo showcased with PDFViewer component, thanks to Sakshi. <@W4SG81T9C> Can you confirm if additional Doc Cloud license required for the same?)\n3. Convert PDF to HTML and show case in Form - <@W4RU4N66R> Anything done similar for HDFC?\n:todo_done: *"}, {"signal_id" : "45812166-be6f-4e5f-b832-09f4c5569f80", "text" : "*\nGo Live Dates:\n17 June for one form\n5 July for another form\n\nThey had multiple issues, for which we delivered a private build.\nThey had additional queries, some of which were resolved, other are a few issues related to repeatability rules via rule editor.\n:todo_done: *"}, {"signal_id" : "97f7021f-85c6-4f8d-bc53-63ce72d3ef68", "text" : "*\n• *Sandbox Environment Access:* Mayank requested access to the sandbox environment for himself, Satya Deep, and Yash. Raciel agreed to provide access to the dev environment and asked for their email addresses.\n• *Form Migration Timeline:* Mayank inquired about the timeline for migrating 700 to 800 forms by July. Michelle confirmed that the timeline has not changed and the forms are currently in DocuSign and another internal system.\n• *Access to Forms:* Mayank asked if the forms are available in the dev environment. Michelle and Raciel clarified that only a sample of 30 to 50 forms is available, and the actual forms are in another tool.\n• *Form Conversion Process:* Mayank and Arneh discussed the process of converting forms into adaptive forms. Arneh mentioned the need to execute the pipeline before adding the forms to the environment.Andy informed Arneh that the pipeline would kick off in the next 15 to 20 minutes and take about 30 to 40 minutes to fully deploy. Arneh planned to do manual steps to enable components on the templates.\n• *Form Testing and QA Cycle:* Mayank asked about the next steps after converting a form into an adaptive form. Andy explained the QA cycle, which includes cleaning up the form, generating a PDF, and running end-to-end tests.\n• *Speed and Efficiency Concerns:* Michelle expressed concerns about the speed and efficiency of AEM in handling forms with many fields. She emphasised the need for a speedy editing cycle and the ability to quickly replace forms.Mayank suggested increasing the frequency of meetings to speed up the form conversion process. He proposed meeting more often to ensure the quality of converted forms and address any issues.\n• *Form Selection for Conversion:* Andy and Arneh discussed selecting a specific form from the box account for conversion. Andy randomly picked a form, and Arneh planned to convert it and share the results.Satya Deep proposed using the Teams channel for rapid communication and feedback on form conversion. Andy and Michelle agreed to try using the Teams channel for notifications and updates.Satya Deep and Raciel discussed the need for access to the box and SharePoint accounts to upload and download forms. Raciel planned to grant access to the team members.\n*Next Steps:* Mayank summarised the next steps, including increasing meeting frequency, using the Teams channel for communication, and ensuring access to box and SharePoint accounts. The team agreed to proceed with these plans.\n:todo_done: *"}, {"signal_id" : "64965afb-4a09-4079-ad50-2a9400df7412", "text" : "*\n*Partner* - Ghost Dynamics\n\n_AI-generated content. Make sure to check for accuracy._\n\n*Key Topics:*\n• *Introduction:* Manu, Vijay Kumar, Pritam, and Deepti discussed the New Zealand Ministry of Social Development project, which aims to onboard professionals and provide employment search services to a significant portion of the New Zealand population. The project involves creating forms and sites for job listings and user profiles. \n• *Customer and Partner Involvement:* Manu confirmed that the customer has involved Ghost Dynamics as a partner for development, with PwC managing the project from a management point of view. The technical team from Ghost Dynamics will be directly interacting with the project team. \n• *Support Channels:* Manu mentioned that the team is interacting with the customer through Microsoft Teams, and there is no dedicated Slack channel created for support yet. \n• *Forms and Sites:* Manu and Pritam discussed the forms and sites being developed for the project. The initial phase involves creating a single form for job listings and user profiles, with potential for multiple forms in the future. \n• *Technical Issues:* Manu and Vijay Kumar reviewed several technical issues related to the forms, including repeatable panel validation, asset visibility, and rule editor problems. They discussed potential solutions and workarounds for these issues. \n• *Asset Sharing:* Deepti raised a concern about sharing assets across multiple sites, as the current configuration only allows assets to be visible in one site. Vijay Kumar suggested a potential solution involving relative paths and CDN configuration. \n• *TinyMCE Extension:* Manu mentioned the customer's request for extending TinyMCE to include custom classes. Vijay Kumar suggested discussing this with the Universal Editor team for potential solutions. \n• *AI Assistant:* Vijay Kumar proposed onboarding the customer to the AI Assistant to help create forms more efficiently. Manu agreed to arrange a demo session with the customer to showcase the AI Assistant's capabilities. \n:todo_done: *"}, {"signal_id" : "adcc051a-9af3-4503-90c4-12f397a3ac91", "text" : "*\nThey had some client library configuration issues, which were resolved in the call.\n:todo_done: *"}, {"signal_id" : "659b1b55-c36d-47c0-baca-d35c06698ac5", "text" : "*\nThey had some queries around their customizations. A few of their issues were fixed. A private release was handed for testing\n:todo_done: *"}, {"signal_id" : "69569251-88ad-449b-aed4-f81de280d84a", "text" : "*\nIssue with custom error response was discussed. Where default AEM error page HTML was being returned instead.\n:todo_done: *"}, {"signal_id" : "a0920f69-b652-47e4-95a7-b23b24dd800e", "text" : "*\nThey had queries around one of the customizations, they wanted to achieve around standardisation of errors.\nVarious approaches with pros and cons were discussed.\n:todo_done: *"}, {"signal_id" : "48462dd1-6b86-4cab-8f4f-9b69f51f2224", "text" : "*\nTheir custom headerlibs and footerlibs were rectified with correct client library configurations.\nThey had some issues with private build, which were discussed.\n:todo_done: *"}, {"signal_id" : "6c807168-30aa-42aa-bd7d-6f489d4dae04", "text" : "*\nGenerated by AI (manually reviewed and udpated).\n\nMeeting notes:\n• *IRS Acrobat Sign Implementation:* Emily summarized the IRS's purchase of Acrobat Sign and their IT team's collaboration with Adobe Acrobat Sign team to roll out phase one of their signature modernization, focusing on internal forms.\n    ◦ *Purchase Details:* Emily mentioned that the IRS purchased Acrobat Sign either earlier this year or at the end of last year, and it was different from the ad math contract. They purchased a separate large enterprise contract for Acrobat Sign.\n    ◦ *Collaboration:* The IRS IT team has been working with Adobe Acrobat Sign team to roll out phase one of their signature modernization, focusing on internal forms. The internal forms team is the same team working on the DMAF side, with similar leadership but different form developers.\n    ◦ *Forms Usage:* The form developers use designer and output XFA forms, with most forms being static due to browser challenges. The phase one involves taking these XFA forms and applying Acrobat Sign, which includes challenges like stripping away accessibility tags.\n• *Challenges with XFA Forms:* Emily discussed the challenges of applying Acrobat Sign to XFA forms, including the stripping away of accessibility tags, and invited questions and comments from the team.\n    ◦ *Accessibility Tags:* Emily highlighted the challenge of applying Acrobat Sign to XFA forms, which involves stripping away accessibility tags. This issue raises questions about the best tool for form development and editing moving forward.\n    ◦ *Team's Input:* Lauren asked whether the signatures are being applied to a PDF document or within the web interface of Acrobat Sign. Emily responded that she would need to review the recorded demo to clarify this.\n    ◦ *Third-Party Tool:* Emily mentioned that the IRS found a third-party tool for form development, which works but is rudimentary. The IRS is asking Adobe if they should use this tool, and the Acrobat Sign team is questioning whether Adobe could create something similar.\n• *Third-Party Tool for Form Development:* Emily mentioned that the IRS found a third-party tool for form development and asked if Adobe could create something similar, leading to a discussion on the best way forward.\n    ◦ *Tool Discovery:* Emily explained that the IRS did their own research and found a third-party tool for form development. She asked if anyone on the team had heard of this tool, but no one had.\n    ◦ *Tool Evaluation:* The IRS tried the third-party tool and found that it works, but they are asking Adobe if it is okay to use it. The team is hesitant to bless the tool due to lack of knowledge about it.\n    ◦ *Adobe's Capability:* The Acrobat Sign team at the IRS asked Emily if Adobe's engineering team could create something similar to the third-party tool. This led to bigger questions about the most effective way forward, whether to continue with acro forms or transition to adaptive online forms.\n• *Adaptive Forms vs. Acro Forms:* Emily and the team debated whether to continue with acro forms or transition to adaptive online forms, considering the level of effort and the investment in adaptive forms for Dmath.\n    ◦ *Form Development:* Emily discussed the challenge of deciding whether to continue with acro forms or transition to adaptive online forms. She emphasized the need to be thoughtful about the level of effort involved and the skill set of the individuals.\n    ◦ *Investment Consideration:* Emily highlighted the investment in adaptive forms for DMAF and the need to consider why different approaches are being recommended for internal versus external forms. She wanted to ensure the team is aligned on the best approach.\n    ◦ *Team's Input:* Lauren mentioned the automated forms conversion service as a possible solution, which Emily clarified was her own idea. The team discussed the pros and cons of using adaptive forms versus Acro forms.\n• *Automated Forms Conversion Service:* Lauren inquired about the possibility of using an automated forms conversion service to turn XFA forms into accessible forms, which Emily clarified was her own idea.\n• *Accessibility and Form Conversion:* Sudhanshu explained the process of converting XFA forms to tagged PDFs using the output API, and the team discussed the potential need for remediation to meet accessibility requirements.\n    ◦ *Conversion Process:* Sudhanshu explained that the form conversion service can convert XFA forms into code compliance-based adaptive forms, focusing on accessibility for the web rendition. He mentioned that the final output can be merged back to a PDF document of record.\n    ◦ *Tagged PDF:* Sudhanshu described the output API, which can generate tagged PDFs from XFA forms, making them accessible. He suggested verifying the output from the third-party tool to ensure it meets accessibility requirements.\n    ◦ *Remediation Needs:* Emily raised concerns about whether alternative text, tabbing orders, and other accessibility features would be retained in the new tagged PDF. Sudhanshu recommended creating sample PDFs to confirm compliance with their requirements.\n• *Licensing and Output Service:* Emily and the team discussed the licensing requirements for using the output service to convert XFA forms to tagged PDFs and confirmed that the IRS contract allows for this.\n• *Multiple Signatures Challenge:* David highlighted the challenge of using adaptive forms with multiple signatures, explaining that the integration between adaptive forms and Acrobat Sign is not seamless.\n    ◦ *Signature Issue:* David explained that adaptive forms fall apart after one signature when using Acrobat Sign, making the integration between adaptive forms and Acrobat Sign not seamless, especially in a multiple signature scenario.\n    ◦ *Team's Input:* Sudhanshu mentioned that core components do not support multiple signers, but he would check with the team to see if there is an option for multiple signers in foundation forms (with support to update fields). Emily and David discussed the challenges and the need for a seamless integration.\n    ◦ *Current Process:* David described the current process where adaptive forms are signed, converted to PDF, and then routed to the next person for signature. He highlighted the complexity and maintenance challenges of this approach.\n• *Next Steps and Internal Alignment:* Emily outlined the next steps, including obtaining XFA form samples, reviewing recordings of previous demos, and having an internal conversation to align on the best approach for the IRS.\n    ◦ *Action Items:* Emily outlined the next steps, including obtaining XFA form samples to run through the output service, reviewing recordings of previous demos, and having an internal conversation to align on the best approach for the IRS.\n    ◦ *Team Collaboration:* Emily emphasized the need for internal alignment and collaboration with the Acrobat Sign PM team. She planned to regroup with Molly and Daniel, the PMs leading the project, to ensure a unified approach.\n    ◦ *Pros and Cons:* Phillip suggested creating a list of pros and cons for each option (maintaining XFA, converting to acro forms, or transitioning to adaptive forms) to present to the customer. Emily agreed and planned to articulate these options clearly.\n\n:todo_done: *"}, {"signal_id" : "61721ec6-2532-4470-a7c8-9a5fbbb4becb", "text" : "*\nDiscussed some of their customisation issues.\nWe have formalized scribble signature contract, the same was communicated.\n:todo_done: *"}, {"signal_id" : "874d64cd-7240-4623-b7ff-288c1f3a0e37", "text" : "*\nPrivate release was pushed on their sandbox environment, customer has validated it on sandbox. Now they want the private release to be deployed on their production environment.\n:todo_done: *"}, {"signal_id" : "babae678-2577-4fee-bf10-67c768612b02", "text" : "*\nMeeting notes:\n• *Troubleshooting Call Update:* Arneh provided an update on a troubleshooting call with Andy and Rachael, mentioning that Core components are now enabled on the dev instance and that they are tracking an issue with a PDF where fields are repeated. The Xfas team is investigating the issue, and Arneh is following up daily.\n    ◦ *Core components enabled:* Arneh mentioned that Core components are now enabled on the dev instance. Andy identified and resolved a transient issue that prevented Arneh's pull request from being processed.\n    ◦ *PDF field repetition:* Arneh explained that a PDF exhibited a behaviour where certain fields were repeated when a specific flag was set to true. The Xfas team is investigating this issue, and Arneh is following up daily to track their progress.\n• *Conversion Errors and New Approach:* Arneh discussed the errors and mistakes in the binding during conversion shown by Andy in previous calls. They have prototyped a new approach that includes generative AI and is expected to be more scalable. \n• *Demo of Experience Builder:* Arneh demonstrated the Experience Builder, showing how to import a form, select a template, and provide additional guidance. The demo included converting a PDF to a form and addressing issues such as field detection and mapping to binding.\n    ◦ *Importing forms:* Arneh demonstrated the process of importing a form using the Experience Builder. This involved selecting a document, choosing a template, and providing additional guidance in natural language.\n    ◦ *PDF conversion:* Arneh showcased the conversion of a PDF to a form, highlighting the ability to detect fields and map them to the appropriate bindings. The demo included examples of single-page and multi-page PDFs, as well as real forms with previously identified errors.\n    ◦ *Manual steps:* Arneh noted that there is currently one manual step required after the form is created, which involves configuring the document of record. This step is expected to be automated in the future.\n• *Field Duplication Issue:* Naveen and Andy discussed an issue where fields like client name and e-mail address were showing up twice in the form. Arneh explained that the fields are named differently but map to the same client name, and the headers are now part of the form.\n• *Manual Edits and Errors:* Arneh highlighted some manual edits and errors in the conversion process, such as missing titles and errors in checkbox groups. They also mentioned issues with transitions between pages and the need for manual edits to address these issues.\n    ◦ *Missing titles:* Arneh pointed out that some titles, such as \"Advisory Account Review Form,\" were not identified during the conversion process, resulting in missing titles in the converted forms.\n    ◦ *Checkbox group errors:* Arneh noted errors in checkbox groups, where additional fields were created incorrectly, and some fields were missed. These errors require manual edits to correct.\n    ◦ *Page transitions:* Arneh mentioned issues with transitions between pages, where fields were included but created new sections incorrectly. Manual edits are needed to address these transition errors.\n• *Handling Repeated Fields:* Andy and Arneh discussed the issue of repeated fields on each page and the need to hide fields on certain pages. Arneh suggested using the Experience Builder to toggle visibility or automate the process.\n• *Incremental Updates and Rules:* Vijay Kumar and Arneh discussed the possibility of making incremental updates using the Experience Builder or predefined rules to apply during the conversion process. This approach aims to help scale the generation of forms.\n• *Concerns and Next Steps:* Andy expressed concerns about the new approach, particularly in handling tables. Naveen suggested providing a list of 30-40 forms for conversion, and Andy proposed a meeting to test the conversion process end-to-end.\n    ◦ *Handling tables:* Andy raised concerns about the new approach's ability to handle tables effectively. He noted that tables are a common point of difficulty in the conversion process.\n    ◦ *Form list:* Naveen proposed providing a list of 30-40 forms that need to be converted in the coming days. This would help prioritise the forms for conversion and testing.\n    ◦ *End-to-end testing:* Andy suggested scheduling a meeting to test the conversion process end-to-end. This would ensure that the new approach works effectively and addresses any issues that arise during the conversion.\n• *Feedback and Automation:* Satya Deep emphasised the importance of active feedback to reduce manual steps and automate the conversion process. Naveen agreed, highlighting the goal of reducing manual work and increasing automation.\n• *Handling Tables in Forms:* Arneh asked about customisations for tables in web forms and suggested using sections instead of tables for better accessibility. Andy confirmed that they do not use special components for tables and agreed to share forms with tables for testing.\n• *Digitalisation and Repeatable Fields:* Vijay Kumar recommended using repeatable fields instead of tables for better digitalisation. Naveen mentioned that their current focus is on converting forms to Adobe and then enhancing them for digital platforms.\n    ◦ *Repeatable fields:* Vijay Kumar suggested using repeatable fields instead of tables to improve digitalisation. This approach would allow for better functionality on digital platforms.\n    ◦ *Current focus:* Naveen explained that the current focus is on converting forms to Adobe to move away from DocuSign. Enhancements for digital platforms will be considered in the future.\n• *Meeting Cadence and Schedule:* The team discussed increasing the frequency of meetings to twice a week and adjusting the meeting time to accommodate different time zones. Naveen agreed to the changes.\n• *Appreciation and Next Steps:* Naveen expressed appreciation for the work done so far and agreed to share PDFs for the next batch of forms. The team planned to continue refining the process and enabling it on the environment for testing.\n\n:todo_done: *"}, {"signal_id" : "aa97e471-426a-4bb5-9dde-539ee85476c2", "text" : "*\nINPS\n\n• *Positive Stakeholder Feedback &amp; Contract Renewal:*\nINPS stakeholders are pleased with the team’s work on various products and are likely to renew the consulting contract until the end of summer.\n• *Adaptive Form Pilot:*\nA new pilot project is being launched for an adaptive form, which will be editable in the private area for customers. This aims to simplify the INPS feedback module.\n• *Phased Implementation Plan:*\nThe adaptive form will be rolled out in phases:\n1. Add a button for redirection to the form.\n2. Allow users to save and resume forms.\n3. Integrate the form’s submit function with the system.\n• *Partner Involvement:*\nThe partner will handle the full implementation of the adaptive form pilot, while the team will deliver a proof of concept.\n• *Batch Processing Implementation:*\nThe batch processing implementation (C# project) is nearly complete, with a final development call scheduled.\n\n*INAIL*\n\n• User Acceptance Testing (UAT) for the batch with the private endpoint is complete.\n• The project is moving into the preproduction phase.\n• The team plans to go live with batch processing by the end of this week or next week (exact date to be confirmed).\n• Emanuele needs to collect data on the expected volume and frequency of batch executions to ensure the system can handle the workload.\n\n:todo_done: *"}, {"signal_id" : "91425e84-dcf2-4941-b36d-99304da0ee36", "text" : "*\nThere is an enhancement required to propagate http error code from custom submit action.\nAdditionally there is an issue where the response header which is used to bypass default error pages of CDN, is being stripped off.\n:todo_done: *"}, {"signal_id" : "13c99776-735e-4a5e-b78b-597aa82297d3", "text" : "*\nWorked with SOP in resolving the issues they were facing with the newer deployment.\nGave a workaround to them to solve nested repeatable panel by custom function. There is an issue in CC based model, where stale indexes  get cached for repeatable panels.\n:todo_done: *"}, {"signal_id" : "f313c424-c068-4c6c-a0da-2e6dcd2775ec", "text" : "*\nHelped them with their review component custimization.\nHelped them to debug and figure out what went wrong in their environments, seems like their customization of page component was breaking including of custom functions added by customer.\n:todo_done: *"}, {"signal_id" : "4ad8eac6-e793-423a-84dc-4567b5522d77", "text" : "*\nGave customer an alternate so that they are un-blocked on error on their Cloudflare CDN. Customer will confirm if that works for them.\nAlternate: check on \"content-type: application/problem+json\" and form submit request url regex\n:todo_done: *"}, {"signal_id" : "1d020f66-5864-40c3-aa05-741846f75648", "text" : "*\n*IDRS Platform Scope*\n\n1. *Pre-processing: Classification &amp; Validation*\n    a. Perform validation checks\n    b. Identify document type\n    c. Apply predefined rules\n2. *Data Extraction*\n    a. Extract structured data\n    b. Perform channel-specific extraction\n3. *Document-Based Data Validation*\n    a. Signature matching\n    b. Stamp data recognition\n    c. Language translation\n    d. Crop signatures and stamps from documents\n    e. Identify handwritten text\n    f. *Example -* Validate if a document includes 3 months of payslips\n4. *Supported Document Types*\n    a. *OVD (Officially Valid Documents):*\n        i. PAN\n        ii. Passport\n        iii. Aadhaar\n        iv. Driving License\n        v. Voter ID\n        vi. RC Book\n5. *Income Documents:*\n    a. Bank Statement\n    b. Salary Slip\n    c. P&amp;L Statements\n    d. Annual Reports\n    e. ITR\n6. *Trade Documents:* (Note: This section was titled but content is not visible)\n    a. Invoice \n    b. CRF\n    c. Transport Doc\n    d. 15CACP\n7. Other Docs\n    a. Shop images\n    b. Invoice\n    c. Cheque \n    d. Margin Money\n    e. Debit note\n    f. Insurance Copy\n    g. Udhyam registration\n    h. Land record\n*CIO/Bank Direction*\n1. Support for both *Assisted* and *Unassisted* journeys\n2. *Shift Left* Strategy via IDRS:\n    ◦ Reject invalid submissions at the earliest stage\n    ◦ Validate all documents upfront\n3. Re-targeting with Agentic AI:\n    ◦ Identify user drop-offs\n    ◦ Use Gen AI to re-engage users\n*Gen AI Lighthouse Program*\n• A distinct initiative running across all major use cases\n*Observability*\n• Enable better observability by standardizing on a common ID\n*5. Account Aggregator Integration*\n\n• Phase 1 of Lead Engine (LE) not adopted\n• KYC engine integrated with multiple backend partners\n• Internal usage of KYC engine continues\n\n\n*API Design Principles*\n• Orchestration APIs will return consistent request/response formats\n• Direct API calls may continue to have varied formats\n*New Project - Sangam*\n\n• Introduce one standard API for:\n    ◦ Prefilling\n    ◦ NTB (New-to-Bank) account creation before offering any product\n• Additional use case under consideration:\n    ◦ For ETB (Existing-to-Bank) users, identify missing data and prompt for it\n• Emphasis on aligning *business (digital product)* teams with *technical* teams\n*Marketing Focus*\n• Personalized targeting\n• Real-time streaming capabilities\n• Adoption of a unified observability platform\n*Offer Decisioning (OD)*\n\n• Shift offer decision latency from *minutes* to *milliseconds (ms)*\n\n:todo_done: *"}, {"signal_id" : "ddd67a49-8d71-4e21-8db3-90d165910c38", "text" : "*\n*Key Topics:*\n• *Introduction:* James, Elisa, Vijay Kumar, and Nitesh discussed the Jet2 account, focusing on the misalignment in expectations and the use of Adobe solutions. They aimed to address the escalation caused by issues with AEM forms and EDS forms. \n• *Jet2 Account Issues:* James and Elisa explained that Jet2 has been experiencing pain points with multiple Adobe solutions, leading to a serious escalation. The main issue was a call around AEM forms where expectations were not met, and the expertise from their side was lacking. \n• *Forms Expertise:* James mentioned that Nitesh was brought in to help with the conversation around EDS forms and the differences between EDS and AEM forms. They aimed to have someone from the product team articulate the differences and recommend the best approach based on Jet2's use cases. \n• *Jet2 Use Cases:* 4 category of forms\n    ◦ Simple data entry forms\n    ◦ Competition forms\n    ◦ Customer service forms, and\n    ◦ Compensation forms. \n         They evaluated the feasibility of using EDS document-based authoring, EDS universal editor, and AEM adaptive forms for each use case.\n• *Recommendation for Jet2:* Vijay Kumar recommended using EDS universal editor for Jet2's forms, as it provides a more intuitive authoring experience and supports various submission types. He also mentioned the possibility of using the Forms Experience Builder, an AI-based tool, to create forms quickly. \n• *Next Steps:* James proposed scheduling a call with Jet2's technical team to present the recommended solutions and address their concerns. They agreed to have an internal regroup before the call to ensure the talk track is spot on. \n\n:todo_done: *"}, {"signal_id" : "823c024a-8b4e-4569-bf90-5432d442b181", "text" : "*\n*Lighthouse Program Overview:*\n• Amritabha provided an overview of the Lighthouse program initiated by the MD and CIO, Ramesh, which includes 16 programs, some of which involve Gen. AI use cases. \n*AI Use Cases in Liability Section:*\n• Dhiraj discussed the need for chat and voice-based support for users on the HDFC portal, including automatic AI bot assistance for users stuck during the account opening journey. \n• The AI bot should offer both chat and voice support, depending on customer preference, and assist with form filling or resume journey in case of drop-offs. \n• The AI should also handle vernacular support for voice interactions. \n*Product Selection and Recommendations:*\n• The AI should help users select the best product variant based on factors like gender, income, etc., and provide detailed features and recommendations without cross-selling other products.\n• The AI should be able to explain product features and answer FAQs based on a feature master. \n*Address Auto-Population:*\n• The AI should auto-populate customer addresses from government documents and prompt users to manually select from a drop-down if the city does not match the master list. \n• The AI should capture the third location for video KYC if the customer is not at their permanent or communication address, and provide a reason for the same. \n*Fraud Detection:*\n• Fraud detection will be handled by the bank's BRE, and AI is not required for this part. \n*Drop-off Assistance:*\n• The AI should assist users who drop off during the journey by initiating a call and connecting them to an RM to complete the onboarding process. \n*Cross-Sell Recommendations:*\n• The AI should recommend cross-sell products like credit cards and insurance based on the user's profile and journey inputs. \n*Use Case:*\n• The primary use case involves enabling chat and voice-based AI support for users during the account opening journey on the HDFC portal, including assistance with form filling, product selection, address auto-population, video KYC, fraud detection, drop-off assistance, and cross-sell recommendations. \n\n:todo_done: *"}, {"signal_id" : "7f19ff33-4a7b-417a-975b-b99c87d6f5ad", "text" : "*\n*Meeting Objective*\nTo resolve connectivity issues between Carpenter’s Adobe Experience Manager (AEM) instance and their Azure SQL Server database, and to clarify the correct integration approach.\n\nKey Discussion Points\n• Current Issue: Carpenter is unable to connect AEM to their Azure SQL Server. The “Sources” option in Adobe Experience Platform (AEP) was not provisioned for their account, leading to confusion about the correct integration path.\n• Clarification from Adobe:\n    ◦ The AEP “Sources” feature is not the correct method for connecting AEM to Azure SQL.\n    ◦ Instead, the connection should be established using Form Data Models (FDM) within AEM.\n    ◦ Configuration must be done via code (Git/VSTS), as there is currently no UI for this setup.\n• Technical Demonstration:\n    ◦ Adobe demonstrated how to configure the Azure SQL connection using environment code, connection strings, and pipelines.\n    ◦ Once configured, the database can be accessed through FDM and used in adaptive forms for CRUD operations.\n• Security Considerations:\n    ◦ Discussion around whether the Azure SQL Server should be accessible via public IP or through more secure means (e.g., private IP, API wrapper).\n    ◦ Carpenter prefers not to expose the database via public IP.\n• Alternative Options:\n    ◦ Adobe suggested using SharePoint Lists for simpler data like picklists.\n    ◦ Wrapper APIs over Azure SQL were also discussed as a way to limit data exposure.\n• Environment Setup:\n    ◦ Carpenter is still setting up their local dev environment.\n    ◦ They expressed a preference to work entirely in the cloud if possible.\n    ◦ Adobe explained that front-end development can be done in the cloud using Edge Delivery Services, but back-end customization still requires a local environment.\n\n:todo_done: *"}, {"signal_id" : "415db4f5-a13f-4a6a-9aba-03ed22c2204f", "text" : "*\n• The call centred on 3 tech approaches:\n    a. EDS Document-based Forms\n    b. EDS Universal Editor Forms \n    c. AEM Adaptive Forms – Core Components (Cloud)\n• Vijay (forms product team, Adobe) gave a demo on each before including Form Experience Builder, Nitesh (field engineering, Adobe) shared a like for like comparison of compatibility against each of your 4 use cases.\n• Recommendation (clear winner) was adoption of EDS universal editor forms.\n• Recommended Jet2 to join Forms Experience AI Beta program – Jet2 to confirm (no commercial implications whilst in BETA phase) \n• Offered VIP programme partnership on forms – dependency on a clear go live date (alternative is a one-time workshop with the product team/ongoing Ultimate support)\n:todo_done: *"}, {"signal_id" : "cc690437-b4ee-4971-b789-c28467c3f184", "text" : "*\nGuided them over, how to achieve their targeted usecases in DoR.\n:todo_done: *"}, {"signal_id" : "2ec9ed3d-6e36-4347-ba80-a51f0bc10558", "text" : "*\nForms overview, including \"Forms Experience Builder\" and \"Forms Optimizer\" was shared by Arun.\nDemo was given for Core Component based AF version of their current forms. Rule, DoR, FDM capabilities were highlighted.\n:todo_done: *"}, {"signal_id" : "750d12ce-bb52-4368-8973-f35ff3b0053f", "text" : "*\n• *Forms Conversion Progress:* Satya Deep provided an update on the conversion of 15 out of 19 forms, noting that some manual work is required to address gaps in the automated conversion process. They aim to reduce the manual effort needed after form conversion.\n• *Binder and Dor Binder Requirement:* Satya Deep mentioned that the team is working on a PR to implement changes for the binder and door binder requirement. They need input from Naveen's team to understand what should be populated into the attribute groups.\n• *Adobe AI Capabilities:* Naveen inquired about leveraging Adobe AI capabilities, and Satya Deep confirmed that it is enabled and can be tried out. However, some manual intervention may be required to make the forms fully functional.\n• *Guide Bridge Change:* Satya Deep mentioned an open item related to the guide bridge, which has been merged and is available for use.\n• *Forms Conversion Demonstration:* Mayank demonstrated the conversion of forms, highlighting that 15 out of 19 forms were converted successfully. The remaining forms were too large and require the implementation of async functionality.\n• *Dark Theme Issue:* Mayank addressed the dark theme issue, explaining that the theme depends on the system settings. If the system is set to dark mode, the form will appear in dark mode.\n• *Form Conversion Flakiness:* Satya Deep and Mayank discussed the flakiness in form conversion, noting that retrying the conversion process usually resolves the issue.\n• *Adobe Sign Integration:* Naveen confirmed that the forms will use Adobe Sign for e-signatures. The user will fill out the form in HTML, and the form will be sent for e-signature using Adobe's API.\n• *Manual Effort in Form Conversion:* Raciel and Mayank discussed the manual effort required to delete repeated fields like account numbers. They suggested providing guidance during the import process to avoid manual deletion.\n• *Repeatable Panels Limitation:* Mayank mentioned a limitation in converting repeatable panels, where the same rows are converted multiple times instead of being implemented as repeatable panels.\n• *Multisigners Issue:* Mayank reported an issue with multisigners, which is being investigated by the internal team. They hope to provide an ETA for the solution by the end of the week.\n• *Testing and Feedback:* Naveen and Raciel agreed to test the converted forms and provide feedback. They will also share additional forms for conversion and testing.\n• *Future Plan:* Naveen mentioned that they have approximately 1500 forms to test with Adobe AI capabilities. They aim to address manual tasks using AI to meet tight timelines.\n\n:todo_done: *"}, {"signal_id" : "906ee0db-a886-404e-8ddf-09c5e262b233", "text" : "*\n• Vijay showcased the latest innovations of IC on cloud with new structural change of json based storage and highlighted that most of the requested features by NFCU being delivered.\n• Showcased the features like \n    ◦ Fragments\n    ◦ FDM integration\n    ◦ Font support\n    ◦ Formatting support like strikethrough\n    ◦ Rule Editor, data based show/hide of fragments\n    ◦ PDF preview using IC rendering API\n• NFCU was really happy to see the progress with comments from Sharmila \"This is good progress and we are now confident to use IC for more usecases of other departments\" \"Thanks for all the support and partnership\"\n• There were few other requirements from NFCU like\n    ◦ Locking the Template editing by Letter Authors\n    ◦ Associate UI usecase\n    ◦ Role based access\n    ◦ When this would be GA\nThanks to <@WE163TH43>, <@U03Q109GQMT> and team for presenting the demo\nOverall *team-IC* which has put on tremendous effort for past few months with multiple Architectural meetings, multiple canvases being created to track the dependencies, completion of work, testathon, etc. Its great to see the outcome and positive feedback from the customer.\ncc: <@WQWCBV6NN> <@W9QMZFR39> <@W4RSW3ECC>\n:todo_done: *"}, {"signal_id" : "b31abb26-07b0-4c96-9d9d-65377ec2693f", "text" : "*\n• TravelPort wants to modernize their forms - and highlighted the concerns:\n    ◦ Do we have an immediate solution to avoid the IE11 requirement (they render the XDP as PDF currently)\n    ◦ Do we have a long term solution - which is responsive and path to AF\n• Mentioned that if we do not have a solution - they would proceed to evaluate other options.\n• They are also open to movement to Cloud (technically - but separate Sales discussion has not happened) - currently on 6.3 - On-prem.\n• After thought - would cache work with prefill in MF - I guess no - so need to check performance with prefill - and we may need to work on it on CS (since their form is very large and mostly prefilled) - <@W6CBB4953> any thoughts.\nProposal shared:\n• Move to MF for now - highlighted that memory requirements may be high - and needs to be verified with:\n    ◦ Data\n    ◦ on CS\n• Need to review and share forms with them (MF - with Form &amp; Fragments) - so they can evaluate on their side\n• We would be sharing the build on 6.5\n• We would review some of the scripts they share - and review the changes that are required (manually) - for migrating these to Adaptive Forms.\nThey have a very large form - with lots of fragments and cannot split the form - and the form is like an application which does a lot of analysis and then the complete flow is the form itself to identify the best deals for the customer.\n:todo_done: *"}, {"signal_id" : "52d1e9a6-568f-40f5-a633-fb9b0b33a414", "text" : "*\nPresenter: *Ken Woodward*\nProject Lead: *Andrei Bogdan*\n\n• Ken introduced Sites Optimizer - since some of the participants had not seen the UI earlier, and were not aware of the capabilities. It was a short 30 mins call - do most of the time was spent on introducing the Sites Optimizer to them.\n• They were quite interested in the SEO, Broken backlinks and related opportunities and were especially interested in the auto-fix part of the opportunities.\n• The various opportunity categories were shared with the customer, and they have access to the UI now. They would be reviewing and identifying the specific stakeholders for each opportunity to continue the discussion (engagement plan for 3 weeks).\n• They asked for more fine grained control for the UI - allowing specific stakeholders to have access to specific opportunities (to ensure wrong persona does not mark an opportunity as invalid) - since they have specific teams for different opportunities.\nFrom forms side - we have identified and updated the ASO UI with 2 opportunities:\n• Newsletter form having low views\n• Forms Accessibility opportunity (identified from AXE-Core)\ncc: <@W4RSW3ECC> <@W6CBB4953> <@W4RT1B152>\n:todo_done: *"}, {"signal_id" : "feb33d43-003b-40d0-92cb-57346ef5061d", "text" : "*\n• Pankaj showcased the Save As Draft along with USC customisation demo to IRS and Accenture Federal team.\n• Additionally, we highlighted two *enhancements* made while delivering this feature, specifically to address IRS requirements:\n    ◦ *Support for Request Object in Save Data API:* During our analysis of the IRS codebase, we noticed they had implemented additional code to support the request object in the Save Data API for Foundation-based forms. We have now added this support out-of-the-box, so no custom implementation is needed from their side. This will reduce the effort to create new servlet for core component based form to request attribute. ( Reducing ~300 lines of Code)\n    ◦ *Reusable Sample Implementation:* The shared sample implementation converts Core Component-based POJOs into Forms Foundation-compatible POJOs and calls Metadata and Data APIs. This aligns with IRS’s existing customization, so they can use it as-is without requiring further modifications.\n• Demo was well received and all the collaterals have been shared.\n• Vara (IRS) was also present and highlighted concerns regarding multiple Feature Toggle, which we clarified that Adobe will support the same and all these enhancements will be part of subsequent Feature Pack release and this HF needs to be validated on non-production environment first.\nThanks <@U04P75X4H1B> and <@WLWHN4TV3> for great work in delivering this feature backport on 6.5 for CoreComponents along with support of customisation on priority basis which was very critical for IRS.\ncc: <@W4RU4N66R> <@W4RSW3ECC>\n:todo_done: *"}, {"signal_id" : "1cd08c2a-b46f-4273-a989-d45804bfd4ae", "text" : "*\nIn the meeting, we provided a comprehensive walkthrough of the newly introduced features and discussed each in detail. The key features covered include:\n• Template creation workflow\n• Fragments &amp; Converting fragment as Object\n• FDM Integration &amp; corresponding data binding\n• Font Support to generate pixel perfect PDF\n• Formatting Enhancements (e.g., font size adjustments)\n• Rule Editor – including data-driven show/hide setvalueof , setPropertyof,clearValueof etc... functionalities.\n• PDF Preview using the IC Rendering API\nIn addition to feature demonstrations, we also discussed:\n• *Archetype Updates* – including new bundle versions\n• *Template Generation Workflow* *Updates*– with guidance on incorporating these changes into the client environment\n• *Importing Existing XDPs* – steps and best practices were shared\n*Client Feedback and Requests:*\n• *Template Locking Feature:* NFCU requested the ability to lock template editing for Letter Authors.\n• *Custom Font Size Requirement:* NFCU expressed the need for more flexible font size settings (i.e custom font size) beyond the current dropdown options.\n\n:todo_done: *"}, {"signal_id" : "cba90d6f-535e-436e-9b43-ba863de67c6c", "text" : "*\nDebugged their issues. Identified a product issue along with their customization issues.\n:todo_done: *"}, {"signal_id" : "8a8ab526-8fe7-42cf-826d-b7de038b429a", "text" : "*\n• Answered queries regarding implementation of custom components in EDS via UE. They had implemented a few but without following the right approach which caused a lot of issues in the code for them.\n• Helped them with discovery of functionalities within rule editor for their use cases.\n:todo_done: *"}, {"signal_id" : "0455a270-6eb0-4bcc-a22b-9fb5e8e3e2ee", "text" : "*\n• *Local Test Harness Setup*: Satya Deep and Raciel discussed the local test harness setup. Satya mentioned that they had set it up and tested a couple of forms. They observed that all fields were populated for one form, but some fields were missed for another. Yash has been working on a fix, and the PR is already merged. Once deployed, the issue should be resolved.\n• When Raciel tried the same form which was working for Satya and Yash, for him the pdf was coming blank.\n• *Code Review and Updates*: Mayank and Satya Deep reviewed the code and identified that the latest changes were not reflected in the JavaScript for the URL. They suggested updating the code to the latest develop branch and redeploying the test harness.\n• *Local Code Check*: Raciel was advised to check the local code and ensure it was running the latest develop branch. This involved pulling the latest changes and redeploying the test harness.\n:todo_done: *"}, {"signal_id" : "55780525-ab17-4d84-8d26-a86fd2c1b0c3", "text" : "*\n1. NFCU has successfully completed the archetype changes on top of their existing Archetype version 52, *enabling full* use of the IC Editor.\n2. Harish and Adarsh from NFCU reported a 401 error while accessing the editor. Upon checking Splunk logs on the call, we found that they were not part of the `forms-user` group. This was communicated to their team. Shubham Nilkanth had the permissions, was there in the call, we checked the *whole flow* was working fine for him.\n3. A few issues were observed while importing XDPs created using the legacy Designer into the IC Editor:\n    ◦ Text appeared vertically aligned. This is due to feature differences between the legacy Designer and IC Editor. \n    ◦ A 500 error occurred when attempting to save the imported XDP. We clarified that the Import XDP feature is primarily intended to support reuse of XDPs created using the IC Editor, not legacy Designer XDPs.\n4. NFCU requested to increase the meeting frequency to four times a week. While we questioned the necessity of this, they were persistent in their request. The frequency has been increased to three meetings per week :slightly_smiling_face:\n:todo_done: *"}, {"signal_id" : "ebe1464e-093a-42be-8f81-d793d3406e40", "text" : "*\nGenerated by AI. Make sure to check for accuracy.\nMeeting notes:\n• *Bindings Issue:* Satya Deep and Raciel discussed the bindings issue, with Satya suggesting reimporting the form with a different name to ensure the bindings work. Raciel agreed to try this approach.\n    ◦ *Reimporting Forms:* Satya Deep explained that reimporting the form with a different name might resolve the bindings issue. He mentioned that the backend code queries the JCR to find the form, and if the form is reimported with the same name, it might find the old one, causing the problem to persist. Raciel agreed to try reimporting the form with a different name.\n    ◦ *Testing Imported Forms:* Raciel asked if he could delete the converted forms if they were to be imported again. Satya Deep confirmed that it was possible and suggested testing the already imported form in the Adobe Yash folder. Yash confirmed the location of the form, and Raciel agreed to test it.\n• *Test Harness Changes:* Andy and Raciel examined the test harness changes, with Andy confirming that the data looks decent and the bound data is coming across fine.\n• *Special Characters in Bindings:* Andy, Yash, and Raciel discussed the issue of special characters in bindings, with Yash confirming that special characters should be enclosed in quotes. Andy suggested checking if the fields with special characters are causing the issue.\n    ◦ *Quotes in Bindings:* Andy and Yash discussed the need for enclosing special characters in quotes for bindings. Yash confirmed that for AF2, special characters in the bind reference should be enclosed in quotes. Andy mentioned that document of record bind references do not need quotes, but previous bind references had a dollar period, and they need to check if quotes are causing the issue.\n    ◦ *Checking Field Names:* Andy asked Raciel to check the field names in the adaptive form to ensure they match. Raciel found small changes, such as a dash, that might be causing the issue. Andy suggested checking if the fields with special characters are causing the problem.\n    ◦ *Testing Fields:* Yash suggested filling other fields to check if all fields are not coming or just a few. Andy noted that fields without special characters showed up correctly, while those with special characters did not. Raciel confirmed that fields with underscores in the table were not working.\n• *Comparing XML Data:* Satya Deep and Andy suggested comparing the XML data being sent in cases where it works and where it doesn't to identify any differences. Andy provided the XML data for comparison.\n    ◦ *XML Comparison:* Satya Deep suggested comparing the XML data being sent in cases where it works and where it doesn't to identify any differences. Andy provided the XML data for comparison and asked Raciel to paste the XML data for Satya Deep to review.\n    ◦ *Exporting XML Data:* Andy explained that the XML data used was generated from the adaptive form and no changes were made to it when sending it to the communication service. He suggested checking if the XML data needs to be converted back to JSON before sending it to the communication service.\n• *Communication Service Issue:* Andy and Satya Deep discussed the issue with the communication service, where the XML data works in the adaptive form but not when generating the PDF. Satya suggested checking the XML being sent to the communication service.\n    ◦ *Generating PDF:* Andy noted that the XML data worked in the adaptive form but not when generating the PDF. Satya Deep suggested checking the XML being sent to the communication service to identify any issues. Andy confirmed that the XML data was not different and suggested checking if any changes were needed in the generate PDF servlet.\n    ◦ *Communication Service:* Andy explained that the Java API calls the communication service and sends the XML data. He noted that bindings with special characters were not getting picked up when generating the PDF, and suggested checking the XML data being sent to the communication service.\n• *Error Toast Issue:* Satya Deep provided an update on the error toast issue, stating that the internal authoring team is looking into it and will follow up with a solution.\n• *Sign Field Issue:* Satya Deep updated that the team has figured out a solution for the sign field issue and is working on a fix, which should be deployed by 11th July.\n• *Manual Step for Door Bindings:* Satya Deep mentioned that the team is working on automating the manual step of associating the PDF with the adaptive form to ensure the door bindings work.\n• *Team Availability:* Satya Deep informed that the team had been occupied with hackathon activities, but they should be back next week, which will help in making progress on the issues.\n• *Adobe AI Capabilities:* Naveen inquired if the Adobe AI capabilities will be useful after 11th July, Team decided to reconnect on 8th July to assess the progress.\n\n:todo_done: *"}, {"signal_id" : "d46a7cdb-b15b-40bb-9f2d-b14d0a4ade22", "text" : "*\n• *PDF Conversion Issues:* Darshan and Andy discussed the issues related to converting Word documents to PDFs, including formatting problems and the need for cleanup. They also explored options for retaining signature fields in the converted PDFs.\n    ◦ *Conversion Process:* Darshan and Andy discussed the process of converting Word documents to PDFs, highlighting the use of a tool to convert Word to PDF. Andy mentioned that the converted PDFs received have acro fields, which are then opened with a designer for further modifications.\n    ◦ *Formatting Issues:* Andy explained that selecting the second option during conversion often leads to significant cleanup due to formatting issues. This problem persists even with the regular flow layout, necessitating retesting to address the formatting challenges.\n    ◦ *Interactive Forms:* Andy demonstrated how to create an interactive form with fixed pages to maintain the visual layout. This approach helps prevent the flow from getting messed up during the conversion process.\n• *Retaining Signature Fields:* Darshan and Andy examined the workaround for retaining unsigned signature fields in PDFs, noting that the current implementation checks if the template is XDP and sets the retain flag accordingly.\n    ◦ *Workaround Implementation:* Andy explained the workaround implemented to retain unsigned signature fields. The system checks if the template is XDP and sets the retain flag to true only for XDP templates. This ensures that the signature fields are retained in the converted PDFs.\n    ◦ *Signature Field Retention:* Andy clarified that the workaround involves setting the retain flag to true for XDP templates, which prevents the removal of acro field signature fields during conversion. This approach ensures that the original signature fields are preserved in the final PDF.\n• *PDF Types and Issues:* Darshan explained the different types of PDFs and the issues caused by converting Word documents to PDFs and making changes in Designer. Engineering is investigating the issue and will provide a fix.\n    ◦ *PDF Types:* Darshan discussed the various types of PDFs, including those converted from Word documents and those modified using Designer. He highlighted that PDFs converted from Word documents and then modified in Designer become a special kind of PDF, leading to specific issues.\n    ◦ *Engineering Investigation:* Darshan mentioned that the engineering team is investigating the issues related to these special PDFs. The team is working on identifying the root cause and will provide a fix to address the problems encountered during the conversion and modification process.\n• *Adaptive Forms and Signature Fields:* Mayank and Andy discussed the process of converting PDFs into adaptive forms and the need to remove signature fields from the adaptive forms to ensure proper signing after PDF generation.\n    ◦ *Conversion Process:* Mayank and Andy discussed the process of converting PDFs into adaptive forms. They emphasised the importance of removing signature fields from the adaptive forms to ensure that signing occurs after the PDF is generated, rather than during the form-filling process in the browser.\n    ◦ *Signature Field Removal:* Andy agreed with the suggestion to remove signature fields from the adaptive forms. This approach prevents the end user from signing the form in the browser, ensuring that the signing process is completed after the PDF is generated and merged with the filled form data.\n• *Text Tagging for Fields:* Andy and Manu explored the use of text tagging for fields in PDFs, including name, initials, and date signed, to automate the population of these fields during the signing process.\n    ◦ *Text Tagging:* Andy and Manu discussed the use of text tagging for fields in PDFs, such as name, initials, and date signed. This approach automates the population of these fields during the signing process, ensuring that the correct information is filled in automatically.\n    ◦ *Field Automation:* Andy explained that the current implementation uses text tagging to automatically populate fields like initials and date signed. This reduces the need for manual entry and ensures that the fields are correctly filled during the signing process.\n• *Acro Forms and Authoring Team:* Andy explained the process of tagging signature fields in acro forms and the role of the authoring team in selecting and configuring these fields before sending the PDF to Adobe Sign.\n    ◦ *Tagging Process:* Andy described the process of tagging signature fields in acro forms. The authoring team selects the signature fields and configures them based on the requirements. The system then automatically detects and tags these fields before sending the PDF to Adobe Sign.\n    ◦ *Authoring Team Role:* Andy highlighted the role of the authoring team in selecting and configuring signature fields. The team uses an authoring UI to specify the fields, and the system automatically adds the necessary tagging for these fields before the PDF is sent to Adobe Sign.\n• *End-to-End Testing:* Mayank and Raciel discussed the challenges faced during end-to-end testing of the converted forms, including issues with special characters and bindings that prevented successful signing in Adobe Sign.\n    ◦ *Testing Challenges:* Mayank and Raciel discussed the challenges encountered during end-to-end testing of the converted forms. They identified issues with special characters and bindings that prevented successful signing in Adobe Sign, highlighting the need for further investigation and resolution.\n    ◦ *Special Characters:* Raciel mentioned that the presence of special characters in the forms caused binding issues, which in turn prevented successful signing in Adobe Sign. The team is working on addressing these issues to ensure smooth end-to-end testing.\n• *Retaining Signature Fields for All PDFs:* Mayank suggested removing the XDP check and setting the retain flag to true for all types of PDFs to avoid issues with signature fields appearing twice or not being clickable.\n    ◦ *Retain Flag:* Mayank suggested removing the XDP check and setting the retain flag to true for all types of PDFs. This approach aims to avoid issues with signature fields appearing twice or not being clickable, ensuring that the signature fields are correctly retained in all PDFs.\n    ◦ *Implementation Plan:* Andy agreed to prepare for the change suggested by Mayank. Until the fix is implemented, the team will continue checking the template type to determine whether to set the retain flag to true or false.\n• *Sharing Source Documents:* Darshan requested Andy and Raciel to share the source Word documents and the original PDFs to help investigate the issues further. They agreed to check with their team and share the required documents.\n• *Table Component Issues:* Mayank explained the issue with table components in adaptive forms, where the fields in the table are not properly mapped, causing data to be missing in the generated PDF. They are investigating the solution.\n    ◦ *Table Component:* Mayank explained that the table component in adaptive forms is not properly mapped, leading to missing data in the generated PDF. The issue arises because the table fields are converted into individual fields, causing a mismatch in the field names and bindings.\n    ◦ *Investigation:* The team is investigating the solution to the table component issue. They are exploring the possibility of converting table fields into repeatable panels, allowing users to add entries dynamically and ensuring that the field names are correctly mapped.\n• *Testing Without Table Components:* Mayank suggested testing the conversion and data population process with PDFs that do not have table components to ensure that other fields are correctly filled in the generated PDF.\n    ◦ *Testing Approach:* Mayank suggested testing the conversion and data population process with PDFs that do not have table components. This approach aims to ensure that other fields are correctly filled in the generated PDF, helping to isolate and address the table component issue.\n    ◦ *Field Population:* Mayank recommended focusing on PDFs without table components to verify that all other fields are correctly populated in the generated PDF. This step will help identify any remaining issues and ensure that the conversion process works as expected for non-table fields.\n• *Async Feature for Large Forms:* Mayank mentioned the implementation of an async feature for converting large forms, which will allow the conversion of forms with 40+ pages. This feature is expected to be available soon.\n• *Next Steps:* Vijay summarised the next steps, including identifying fixes for the two ongoing issues, converting large PDFs, and testing the entire process except for signing. Andy will test a new form and report back.\n\n:todo_done: *"}, {"signal_id" : "7f8599df-4bbd-4eed-9426-34c97d0da134", "text" : "*\n*Deskside Coaching - AEM Translation*\nAgenda:\n• Sites\n    ◦ *Overview AEM Translation Framework* : Learn how AEM handles multilingual content using Translation Projects and integration with translation providers.\n    ◦ *Executing Translation for Sites (with Demo)* : Hands-on session on translating AEM Sites using translation workflows and automation.\n    ◦ *Translating Content Fragments (with Demo)* : How to localize structured content using Content Fragments and manage their translation lifecycle.\n    ◦ *Translating Digital Assets (with Demo)* : Managing asset metadata and visual content across multiple languages using AEM Assets workflows.\n    ◦ *Setting Up New Languages for Sites :* Guidance on enabling new locales: creating language roots, language copies, and configuring translations.\n• Forms:\n    ◦ *Using Translation in AEM Adaptive Forms :* Overview of translating AEM Forms using built-in i18n support and custom resource dictionaries.\n    ◦ *Setting Up New Languages for AEM Forms :* How to configure new language options specifically for Forms — including resource files and locale setup.\n\n:todo_done: *"}, {"signal_id" : "8b4da9d4-e16e-4374-8604-dda85de7dab1", "text" : "*\nNFCU went live with their first AF usecase\n<https://www.navyfederal.org/forms/lending/ccdr/ccdr.html>\n\nIn the meeting NFCU, highlighted few other requirements and they mentioned that there is good traction among other departments after the success of AF and IC.\n• Deploy IC latest build on Dev2 and QA env\n• Need closure on ongoing Theme issue - Issue is pending with CloudManager team\n• Automated Custom Metadata which is readonly\n• Manual Letter generation - It appeared to be Associate UI usecase, Chris shared the mocks and we shared 6.5 AgentUI documentation\n• Sharmila also wanted to have discussion around AEM Projects, for which we re-directed to reach out to TAM.\n• NFCU also showed a list of other requirements around IC\nWe emphasised in the meeting that, it would be helpful to share all such requirements over email, with detailed usecase and in priority order, so that we can discuss the solution in the meeting.\n:todo_done: *"}, {"signal_id" : "e2b30d8b-3c87-42bd-8188-a52ea818c22f", "text" : "*\n*PDF Conversion Issues:* Mayank and Andy discussed the issues with PDF conversion, specifically the multiple sign-up fields and the XML generated with respect to the table component. Andy confirmed that the previously converted forms are live and they are continuing to use the other process while trying to get the AI going.\n\n*Table Component Issue:* Mayank and Andy discussed the issue with the table component in the forms. Andy explained that they have not implemented any table as of such in the current round for RIA forms and are using specific field names instead of repeating field names.\n.\n*Conversion to Core Components:* Mayank confirmed that for the new set of forms using AI, they are OK to convert them into core components. Andy agreed as long as it works.\n\n*XML Notation for PDF Service:* Mayank shared the updates on the table component issue and explained that they have tried with a specific XML notation and it is working for them. Andy confirmed that if the XML is not converted to this particular format, it requires PDF processing at the service level.\n\n*Changes in Workbench Standalone and Optional Code Bases:* Andy mentioned that the changes required for the table component issue would need to happen in the Workbench standalone and optional code bases. Michelle suggested taking up the decision with Naveen.\n.\n*Effort for Changes:* Andy estimated that the effort for the changes would be one point and it would have to go through a release cycle. Michelle agreed and mentioned that they would need to coordinate with other teams on timing.\n\n*Testing and PR Creation:* Mayank and Andy discussed the testing and PR creation process. Mayank mentioned that Yash would create a PR and share it in the teams channel for review. Andy confirmed that he would handle the PR and all of that.\n\n*End-to-End Testing:* Mayank requested Andy to try end-to-end testing of any form that does not have a table component to see if they are facing any other issues. Andy mentioned that he has not had time to do that in the last two days.\n.\n*Multiple Signer Part:* Mayank mentioned that the team would be able to share the release for the multiple signer part by 16th July and they would pass on the release to Andy for testing.\n.\n*Coordination for Testing:* Andy and Mayank discussed the coordination for testing the release for the multiple signer part. Andy mentioned that they would need to remove their workaround for testing.\n.\n*Uploading Word Document:* Andy mentioned that he would find a place in assets to upload the Word document and ping the link in AM. Satya Deep suggested using the teams channel as well.\n.\n*Next Meeting:* Mayank mentioned that they would share the PR by today or tomorrow and requested Andy to share the update on whether the things are working end-to-end before the next meeting.\n:todo_done: *"}, {"signal_id" : "8b3f87e0-5a39-4223-9c02-0c23869855c1", "text" : "*\nAttendees\n• *Colin Vlasak* – Marketing Owner, Stericycle &amp; Shred-it\n• *Dillon Sorensen* – Colin’s Manager, Waste Management (parent company of Stericycle)\n\n*Meeting notes*\n\n*Explained Site Optimizer:*\n• Demonstrated how Site Optimizer uses operational telemetry and AI analysis to surface accessibility and conversion opportunities.\n• Clarified the Early-Access “Forms Optimization” program: our team will both run experiments and implement fixes, given that we have required access.\n*Discussed the Opportunities present in Shredit and Stericycle Domains:*\n• Colin understood the opportunities and mentioned that they have been doing that in the past but did not have the bandwidth to do the same after the acquisition. Though he mentioned two important things: \n    ◦ Quality of leads is more important but was open to experimentation given that the sales agrees to it.\n    ◦ For _Forms Navigation_, success will be measured by the combined conversion uplift of the source page *and* the form page, not the form page alone.\n    ◦ Confirmed that experiment data can be integrated with their analytics server.\n*Business KPIs and CPL:* Colin explained that the main KPI for form submissions is the conversion rate, which is monitored to identify trends and trigger deeper analysis if needed. Though shredit has a similar form across all the pages, Stericycle has different measure for different forms.\n\nThey measure CPL from the paid traffic and Colin will supply current *cost-per-lead (CPL)* figures for paid traffic in a follow-up note.\n\n*Experimentation Framework:* Vijay cleared the doubts regarding licensing and availability of experimentation framework in their environment\n\n*Access to Site Optimizer:* Colin  inquired about access to the Site Optimizer, explained that portal access with only Form specific Opportunities is forthcoming; meanwhile, form-specific insights will be shared as documents.\n\nNext Steps:\n\n*Share the Data for Review:* (Colin)\nThey will review the form optimization insights and discuss with the sales team or senior leaders to determine the feasibility of implementing the suggested changes.\n\n*VIP Program Participation:* They will Discuss internally and confirm participation in the VIP program for form optimization testing.\n\n*Follow-up Meeting:* Schedule a follow-up meeting for the week of July 28th to discuss the form optimisation opportunities and next steps.\n\n*Document Authoring (Separate topic than Forms Optimizer)*\nVijay and Colin discussed Document Authoring (Dark Alley) and how they can leverage it for Forms. Vijay will be setting up a separate meeting with them demonstrate those capabilities\n:todo_done: *"}, {"signal_id" : "6141312a-f327-421b-961f-ba7bde0d8959", "text" : "*\n• Model bump and some other improvements radio button getting detected correctly and all options coming in for the radio buttons. \n    ◦ *Action item - Engineering team (changes have been done some test failures did not allow for deploy, targetting this for tomorrow)*\n• Double sign field coming\n    ◦ *Action item - Engineering team has done the fixes, will make it available on LPL environment by 17th July*\n• Once these changes are done end to end testing.\n    ◦ *Action item - LPL team to test the forms end to end.*\n        ▪︎ In this regenerate the form which every you want to test using /import-form\n        ▪︎ Verify the fields are correct and the corresponding bindrefs are correct.\n        ▪︎ Testing the for data coming fine in filled pdfs and signing also working fine on the generarted pdf.\n\n:todo_done: *"}, {"signal_id" : "0458faaa-b2e6-4053-b593-b7e57c517394", "text" : "*\nAttendees\n• Shameem Gouse Lazam Sayyad\n• Shivendra Vikram Singh\n• Kevin Ausburn\nMeeting Notes:\n\n*Introduction:* The team had some knowledge of Sites Optimizer and gave them an introduction of the Forms Opportunities. Shivendra mentioned that it is good that Form Opportunities are also presented within a single tool. They were earlier confused with what Forms is doing vs Sites.\n\n*Sampling in Optel*\nWe emphasised that the analysis and opportunity suggestion is AI driven but since they had low traffic it takes time to collect enough data. There was a question if we can change the sampling rate. We confirmed that it is done during experimentation but generally it is 1% of all site visits\n\n*Opportunities*\nThey wanted to look at the examples of different type of opportunities and we shared with them the drop off analysis and Form Navigation.\nThe Form Navigation Opportunities made total sense to them while it was mentioned that suggestions for the drop off hypothesis has to be proven by an experiment.\n\n*Business KPIs*\nThe team shared the details of the KPIs they currently monitor via an agency which includes navigations within the site pages, field drop offs, conversion rate.\nThey are also interested in time taken to fill a form which they are not able to measure currently\n\n*Integration during development cycle*\nAs they are in the process of modernizing their forms, they wanted to identify certain opportunities before going live as well. They wanted to understand if the tooling can integrate during the development phase (figma designs etc) as they have a huge development process (business justification, processes etc) if something needs to be changed on prod.\n\nWe mentioned that we would be creating a knowledge base once we have proven hypothesis and use that to suggest best practices or common pitfalls during the design phase as well.\n\n*Next Steps*\nThe team liked the idea and wanted to try it out on their environment. We need to enable the FT on their environment. They are also in talks to get a trial version of Sites Optimizer.\n:todo_done: *"}, {"signal_id" : "fbaeeca9-1a3d-4392-aaaa-e7f156dc34f9", "text" : "*\nWe had a connect with 4Point for customer Carpenter to identify the issues they are facing with their could environment.\n• The environments were provisioned around April, and their pipeline is failing since.\n• They have created the pipeline for dev environment - but seems the repo is corrupt/empty - they may have tried to make changes to it.\nEnvironment: <https://aemcs-workspace.adobe.com/customer/program/154535>\nPipeline executions (14th/15th July) - after initial environment creation failed with the error:\n```Executing command mvn --batch-mode org.apache.maven.plugins:maven-dependency-plugin:3.1.2:resolve-plugins\n18:16:58,565 [main] [INFO] Scanning for projects...\n18:16:58,786 [main] [ERROR] [ERROR] Some problems were encountered while processing the POMs:\n[ERROR] Child module /build_root/build/carpentercompanyforms-p154535-uk18879/core of /build_root/build/carpentercompanyforms-p154535-uk18879/pom.xml does not exist @ \n[ERROR] Child module /build_root/build/carpentercompanyforms-p154535-uk18879/ui.apps.structure of /build_root/build/carpentercompanyforms-p154535-uk18879/pom.xml does not exist @ \n[ERROR] Child module /build_root/build/carpentercompanyforms-p154535-uk18879/ui.config of /build_root/build/carpentercompanyforms-p154535-uk18879/pom.xml does not exist @ \n[ERROR] Child module /build_root/build/carpentercompanyforms-p154535-uk18879/ui.content of /build_root/build/carpentercompanyforms-p154535-uk18879/pom.xml does not exist @ \n[ERROR] Child module /build_root/build/carpentercompanyforms-p154535-uk18879/it.tests of /build_root/build/carpentercompanyforms-p154535-uk18879/pom.xml does not exist @ \n[ERROR] Child module /build_root/build/carpentercompanyforms-p154535-uk18879/dispatcher of /build_root/build/carpentercompanyforms-p154535-uk18879/pom.xml does not exist @ ```\nwhich suggests some corruption/mis-configuration in the Repo/Pipeline.\n\nWe shared the documentation around the same.\n• <https://experienceleague.adobe.com/en/docs/experience-manager-cloud-service/content/onboarding/journey/overview>\n• <https://experienceleague.adobe.com/en/docs/experience-manager-cloud-service/content/onboarding/journey/developers>\n:todo_done: *"}, {"signal_id" : "d7704f37-98be-4f08-b6a8-b324bb10f0a0", "text" : "*\n*Meeting Summary* – NFCU Requirements Review\n\nNFCU has shared an Excel sheet outlining their requirements and identifying gaps in the current Interactive Communication (IC) Editor. The we have reviewed the document and sought clarification on the following use cases:\n1.  *Data Mapping*\n    ◦ *Requirement*: Support for data binding using a JSON data model and XSD schema during communication document creation.\n    ◦ *Discussion Summary*: NFCU clarified that they require support for JSON schema only.\n    ◦ *Recommendation*: It was suggested to utilize FDM (Form Data Model) which is a JSON schema, without connecting to an external data source. NFCU can manually create entities within FDM, which should address their use case effectively.\n2. *Batch PDF Generation in Background*\n    ◦ *Requirement*: Generate PDFs in batch/background by authoring IC with a schema and merging data using XML.\n    ◦ *Discussion Summary*: NFCU confirmed that they intend to use JSON as the data format, not XML.\n3. *Content Generation and Formatting Rules*\n    ◦ *Requirement*: Use of a rule editor to apply conditional content rendering (e.g., `if` conditions).\n    ◦ *Discussion Summary*: The rule editor is currently functional on NFCU’s end. They plan to explore it further.\n4. *Render API Integration*\n    ◦ *Requirement*: NFCU has requested guidance on using the Render API as an interface from their servlet.\n    ◦ *Action Item*: Provide documentation for the IC APIs, including usage instructions for the Render API.\n:todo_done: *"}, {"signal_id" : "50bcb622-d35e-40da-8c21-8323530d4efd", "text" : "*\nIn last night meeting with NFCU, they highlighted 2 requirements which are critical for their upcoming golive plans in Oct\n1. Support of IC rendering API to take data.json as input, they want similar experience that of Output API. Their upstream function doesnt allow any API to fetch data due to security concerns, rather they provide they payload of json data which they want to provide to IC rendering API.\n2. Manual letter usecase: where few of the data would be fetched from the system, but few data would be inserted manually and then invoke a workflow. This is exactly Associate UI usecase, where we showcased existing 6.5 documentation and they agreed.\nThey had shared a big list of features, which we asked should be prioritised based on the Journey thats going live, to which Shubham and team from NFCU acknowledge and would provide a list in the timeline order, though all of them are required.\n:todo_done: *"}, {"signal_id" : "13a337b0-6143-4d0d-b7a4-14cb393a6503", "text" : "*\n• *PDF Conversion and Sync Code:* Mayank and Andy discussed the recent fixes and updates related to PDF conversion, including the need to keep the browser open during the process. Mayank mentioned that the async code for long PDFs has been pushed, and Andy acknowledged the update.\n• *Extra Sign Field Fix:* Mayank informed Andy that the fix for the extra sign field has been deployed and prioritised for their program. Andy confirmed understanding and discussed the need for a code reversion in Dev to test the fix.\n• *Radio Buttons and Bindings:* Mayank recommended a workaround for issues with radio buttons and their data bindings. Andy acknowledged the recommendation and mentioned that they have already pulled the code for review.\n• *Forms Versioning and Audit Logs:* Michelle inquired about new features for managing forms from a versioning and restoration perspective. Mayank shared documentation on versioning and audit logs, and Andy requested similar features for PDFs and XDPS.\n\n:todo_done: *"}, {"signal_id" : "3d96ee54-5a34-4b34-80dc-d8f50a6434a4", "text" : "*\nIssues of SOP with latest private release were discussed.\n:todo_done: *"}, {"signal_id" : "6cea9f3f-fcf8-436c-8b42-5ba0222cf949", "text" : "*\n*Usecase:* On-demand creation of company related presentation by internal and external users\n*Volumes:* ~100/month (Tom said it might be more, he will confirm later)\n*Current solution:* MS Office, SharePoint, SFDC marketing cloud storage and user journeys, Siesmic (3rd party tool) for data merge in PPT (<https://www.seismic.com/blog/introducing-seismic-for-powerpoint/>)\n*Languages:* 4 (English, Simplified Chinese, Japanese, Korean)\n*Use-case flow:* \n1. Author\n    a. Create a PPT with static content including text, graphs, images and dynamic placeholders for currency symbols, region and associated data elements like total AUM for a region. \n    b. Create an excel with currency symbols and associated data.\n    c. Enter Siesmic data placeholders using their Powerpoint plugin.\n    d. SFDC user journeys are setup in parallel to trigger PPT generation using Siesmic using input params.\n2. End user: \n    a. There is a form with first name, last name, email and a section to select what all info to include in the final document e.g. about the company, performance in specific regions, currency etc.\n    b. User selects what all to include in the final presentation and their name/email.\n    c. Internal users complete form filling on a SharePoint site and do not have to enter email id - the final presentation is displayed to them within the browser. \n    d. External users complete on a web site and have to provide email id to receive the link of document.\n    e. For requesting non-english versions, they generate the EN version and then go to separate links on main page to download the language specific version which is based on EN content.\n    f. On submitting the EN request, the data is sent to SFDC storage with fist name, last name, email and link of the generated document.\n    g. A user journey is triggered in SFDC to call Siesmic to generate the merged and assembled document PPT.\n    h. Customer was not sure whether PPT was stored by Siesmic or generated on the fly using data in URL. We have observed document can be generated by clicking the link in email received by external users even after sometime.\n    i. The final output is PPT - generated dynamically and data merged into placeholders in the original PPT template.\nCustomer is decommissioning SFDC marketing cloud and want to reimagine this journey as they begin adopting AJO. They mentioned that final PPT generation may be crucial for internal teams as they may use few slides from it during customer discussions but are open to other approaches like PDFs if those slides can be extracted. They asked us to send proposal of what's possible closest match even if use-case cannot be completely retained as-is.\n\nNo requirement to password protect PDF for final output as it is PPT.\n\nOther use-cases for Forms can be explored once this solution is in place.\n\nThey have AEM Sites CS so marketing SKU can also be pitched for external user data capture in addition to core Communications SKU.\n\n<@W4RSW3ECC>, <@W9QMZFR39>, <@W4R5LUPK3>, <@W4RU4N66R> Need thoughts on the final proposal to support authoring in PPT, data merge, disassembly, dynamic assembly and final PPT generation.\n:todo_done: *"}, {"signal_id" : "7de5516f-5215-4f99-b05d-76356ae51bb8", "text" : "*\n1. The customer has not started creating forms yet; they were attempting to enable the Forms Core Component on their development environment.\n2. Their pipeline was failing because they had removed most of the content from the `artifact` project.\n3.  We reverted the corrupt commit and re-ran the pipeline — forms are now enabled on their dev environment.\n4. The customer is also trying to start a local SDK instance, but AEM is not launching for some reason. We recommended using the latest SDK jar, which is working on our local setup.\n\n:todo_done: *"}, {"signal_id" : "e202eea5-7a3d-4c3c-a76f-edcd24b140c5", "text" : "*\n*Meeting notes (AI generated)*\n\n*Custom File Attachment Component Demo*: Shivam and Pankaj demonstrated the custom file attachment component, explaining its functionality and how it uploads files directly to Amazon S3. They showed the codebase and the process of uploading files, validating them, and saving the URLs in the submission data, also explained how would it work with customization.\n\n*Save and Draft Functionality*: Christopher shared his screen to discuss questions about the save and draft functionality. He demonstrated the process of saving a form and rendering drafts, and Pankaj confirmed the correct paths and data references.\n\n*Draft Prefill Service:* Pankaj explained the draft prefill service, which checks for drafts and retrieves data from the unified storage connector to render the form with the saved data.\n\nPankaj offered to review the customization code once Christopher is done with the updates. Christopher agreed and mentioned that he would share the code for review if needed.\n\ncc: <@W4R5LUPK3> <@W4XTCQ07J>\n:todo_done: *"}, {"signal_id" : "dd6df3fb-8254-4cc1-85ac-8cd6e763507e", "text" : "*\n*Introduction to Adobe Forms Team and Demo Agenda:* Deep introduced themselves as an engineer in the Adobe Forms team and outlined the agenda for the demo, which included understanding the authoring of forms using Clark County forms and demonstrating the authoring experience with generative AI features.\n\n*Demonstration of Forms Editor Interface:* Deep demonstrated the forms editor interface, explaining the content tree, properties, and forms experience builder tabs. They showed how to use the generative AI features to author a form using a screenshot of a Clark County form.\n\n*Generating Form Using Generative AI:* Deep demonstrated how to generate a form using a screenshot and the generative AI features. They explained the limitations, such as the need to manually add images and adjust the layout, but highlighted the ease of generating the majority of the form components.\n\n*Dynamic Behaviour and Rule Editor:* Deep explained the concept of repeatable panels and demonstrated how to dynamically add or remove fields using the rule editor. They showed how to delete components and make a panel repeatable, allowing users to add or remove instances of a panel as needed.\n\n*API Integration for Dynamic Form Fields:* Deep demonstrated how to integrate an API to dynamically fill form fields based on user input. He explained the  ability to set required fields, minimum and maximum values, patterns, and custom error messages, as well as the default error messages provided by the system.\n\n*Multi-Step Forms and Wizard Layout:* Deep and Vijay Kumar discussed the concept of multi-step forms using the wizard layout. They demonstrated how to convert a panel to a wizard layout, allowing users to fill out form fields in a step-by-step manner.\n\n*Styling and Custom Components:* Talmiz demonstrated how to change the styling of forms and create custom components. They showed how to use the AEM CLI tool to create a custom component based on an out-of-the-box component and how to manipulate the DOM structure and add custom JavaScript and CSS.\n.\n*Deployment and Testing of Changes:* Talmiz and Vijay Kumar explained the process of deploying and testing changes. They recommended creating a branch for new features, testing the changes using the Universal Editor, and then merging the branch to the main branch for deployment. They also highlighted the importance of ensuring no impact on live forms during deployment.\n.\n*Future Plans and VIP Programme:* Vijay Kumar discussed the future plans for migrating PDF forms to EDS forms and the possibility of participating in the VIP programme. Michael expressed interest in gradually migrating forms and empowering departments to create and manage their own forms.\n:todo_done: *"}]
